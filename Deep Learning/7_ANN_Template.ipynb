{"cells":[{"cell_type":"markdown","metadata":{"id":"Vl3eIEYFkgP7"},"source":["<h1 align='center'><b><font color ='pickle'>Template ANN</b></h1>\n","\n","- This Template can be used to train a model that has stack of Linear Layers. \n","- We will refactor our model so that it becomes easier to add as many layer as we want without changing the model.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FIxAU6f3S-MI"},"source":["# <Font color = 'pickle'>**Load Libraries/Install Software**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:35:35.790529Z","iopub.status.busy":"2022-10-02T10:35:35.790311Z","iopub.status.idle":"2022-10-02T10:35:35.800037Z","shell.execute_reply":"2022-10-02T10:35:35.799579Z","shell.execute_reply.started":"2022-10-02T10:35:35.790485Z"},"id":"silZTZDXNSGU"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T10:35:36.754664Z","iopub.status.busy":"2022-10-02T10:35:36.754227Z","iopub.status.idle":"2022-10-02T10:35:36.760593Z","shell.execute_reply":"2022-10-02T10:35:36.760035Z","shell.execute_reply.started":"2022-10-02T10:35:36.754648Z"},"executionInfo":{"elapsed":161,"status":"ok","timestamp":1665370762737,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"-h5a-vtFb738","outputId":"2c34948e-950b-4cac-db5c-27e1191331a2","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on CoLab\n"]}],"source":["if 'google.colab' in str(get_ipython()):\n","  print('Running on CoLab')\n","else:\n","  print('Not running on CoLab')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:35:37.679455Z","iopub.status.busy":"2022-10-02T10:35:37.679286Z","iopub.status.idle":"2022-10-02T10:35:37.685382Z","shell.execute_reply":"2022-10-02T10:35:37.684911Z","shell.execute_reply.started":"2022-10-02T10:35:37.679443Z"},"executionInfo":{"elapsed":9011,"status":"ok","timestamp":1665370774085,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"q4OpOEo0QktF","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"outputId":"649370d3-af1e-42e6-a911-b3ba323e1100"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.9 MB 5.0 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 96.1 MB/s \n","\u001b[K     |████████████████████████████████| 182 kB 78.1 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 93.0 MB/s \n","\u001b[K     |████████████████████████████████| 158 kB 84.5 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 92.5 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 76.7 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 78.5 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 78.5 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 98.2 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 89.8 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 92.6 MB/s \n","\u001b[K     |████████████████████████████████| 156 kB 85.5 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# Install wandb and update it to the latest version\n","if 'google.colab' in str(get_ipython()):\n","    !pip install wandb --upgrade -q"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T10:35:38.966991Z","iopub.status.busy":"2022-10-02T10:35:38.966806Z","iopub.status.idle":"2022-10-02T10:35:38.974840Z","shell.execute_reply":"2022-10-02T10:35:38.974410Z","shell.execute_reply.started":"2022-10-02T10:35:38.966978Z"},"executionInfo":{"elapsed":14579,"status":"ok","timestamp":1665370788660,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"m7C0tvyKoy6f","outputId":"6df752bf-1cc6-4ea2-979b-5b4d17fe1acb","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mount google drive\n","if 'google.colab' in str(get_ipython()):\n","    from google.colab import drive\n","    drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:35:51.980836Z","iopub.status.busy":"2022-10-02T10:35:51.980539Z","iopub.status.idle":"2022-10-02T10:35:52.005949Z","shell.execute_reply":"2022-10-02T10:35:52.005549Z","shell.execute_reply.started":"2022-10-02T10:35:51.980815Z"},"id":"TqYqOtp5yluv","tags":[]},"outputs":[],"source":["# Importing the necessary libraries\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchtext.vocab import  vocab\n","\n","import random\n","from datetime import datetime\n","import numpy as np\n","import pandas as pd\n","import joblib\n","from collections import Counter\n","from types import SimpleNamespace\n","\n","from pathlib import Path\n","import sys\n","\n","from sklearn.model_selection import train_test_split\n","import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:16.384425Z","iopub.status.busy":"2022-10-02T10:36:16.384181Z","iopub.status.idle":"2022-10-02T10:36:16.406240Z","shell.execute_reply":"2022-10-02T10:36:16.405758Z","shell.execute_reply.started":"2022-10-02T10:36:16.384410Z"},"id":"DMbfI4z8N-a9","tags":[]},"outputs":[],"source":["#if 'google.colab' in str(get_ipython()):\n","#  !python -m spacy download 'en_core_web_sm'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"execution":{"iopub.execute_input":"2022-10-02T10:36:18.366715Z","iopub.status.busy":"2022-10-02T10:36:18.366492Z","iopub.status.idle":"2022-10-02T10:36:19.342975Z","shell.execute_reply":"2022-10-02T10:36:19.342550Z","shell.execute_reply.started":"2022-10-02T10:36:18.366701Z"},"executionInfo":{"elapsed":3916,"status":"ok","timestamp":1665370804756,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"vsr_hAq78XFz","outputId":"d3803b47-0b62-402a-dd91-579d8b901eb0"},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}],"source":["# Login to W&B\n","wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"J2nAIo5uNxEr"},"source":["# <Font color = 'pickle'>**Specify Project Folders**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:21.717528Z","iopub.status.busy":"2022-10-02T10:36:21.716436Z","iopub.status.idle":"2022-10-02T10:36:21.744773Z","shell.execute_reply":"2022-10-02T10:36:21.744138Z","shell.execute_reply.started":"2022-10-02T10:36:21.717511Z"},"id":"zd6c5IGa_iUl","tags":[]},"outputs":[],"source":["# This is the path where we will downlaod and save data\n","if 'google.colab' in str(get_ipython()):\n","  base_folder = Path('/content/drive/MyDrive/data')\n","else:\n","  base_folder = Path('/home/harpreet/Insync/google_drive_shaannoor/data')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:22.513975Z","iopub.status.busy":"2022-10-02T10:36:22.513801Z","iopub.status.idle":"2022-10-02T10:36:22.537843Z","shell.execute_reply":"2022-10-02T10:36:22.537305Z","shell.execute_reply.started":"2022-10-02T10:36:22.513962Z"},"id":"Z0yKILuteTDE"},"outputs":[],"source":["data_folder = base_folder/'datasets/aclImdb'\n","model_folder = base_folder/'models/nlp_fall_2022/imdb'\n","custom_functions = base_folder/'custom-functions'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:23.464470Z","iopub.status.busy":"2022-10-02T10:36:23.464298Z","iopub.status.idle":"2022-10-02T10:36:23.488166Z","shell.execute_reply":"2022-10-02T10:36:23.487795Z","shell.execute_reply.started":"2022-10-02T10:36:23.464457Z"},"id":"1i9tdWEkOha8"},"outputs":[],"source":["sys.path.append(str(custom_functions))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T10:36:24.115920Z","iopub.status.busy":"2022-10-02T10:36:24.115693Z","iopub.status.idle":"2022-10-02T10:36:24.140715Z","shell.execute_reply":"2022-10-02T10:36:24.140380Z","shell.execute_reply.started":"2022-10-02T10:36:24.115905Z"},"executionInfo":{"elapsed":190,"status":"ok","timestamp":1665370858140,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"m8C6e11FOiEX","outputId":"d443daef-4ff9-449e-e0a2-69c5218c4fd5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content',\n"," '/env/python',\n"," '/usr/lib/python37.zip',\n"," '/usr/lib/python3.7',\n"," '/usr/lib/python3.7/lib-dynload',\n"," '',\n"," '/usr/local/lib/python3.7/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n"," '/root/.ipython',\n"," '/content/drive/MyDrive/data/custom-functions']"]},"metadata":{},"execution_count":10}],"source":["sys.path"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:34.241275Z","iopub.status.busy":"2022-10-02T10:36:34.241066Z","iopub.status.idle":"2022-10-02T10:36:34.465547Z","shell.execute_reply":"2022-10-02T10:36:34.464959Z","shell.execute_reply.started":"2022-10-02T10:36:34.241261Z"},"id":"cw-B4qKHOjUC"},"outputs":[],"source":["import custom_preprocessor as cp"]},{"cell_type":"markdown","metadata":{"id":"17xctemopjdA"},"source":["# <Font color = 'pickle'>**IMDB Dataset**\n","\n","For this notebook, we will use IMDB movie review dataset. <br>\n","LInk for complete dataset: http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz.\n","\n","We downloaded the dataset in the previous lecture 2 notebook (notebook: 3_Faster_tokenization_spacy_final.ipynb)\n","\n","We created csv files in Lecture 2 -- train.csv and test.csv file. The files are availible in Lecture2/data folder from eLearning. I have applied the custom pre=processor and cleaned the data set for this lecture. I pickled the datasets and saved them as files. The files are available in Lecture_6/data folder. We will download the following files as well.\n","\n","- 'x_train_cleaned_bag_of_words.pkl'\n","- 'x_valid_cleaned_bag_of_words.pkl'\n","- 'x_test_cleaned_bag_of_words.pkl'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:46.079612Z","iopub.status.busy":"2022-10-02T10:36:46.079371Z","iopub.status.idle":"2022-10-02T10:36:46.104603Z","shell.execute_reply":"2022-10-02T10:36:46.103997Z","shell.execute_reply.started":"2022-10-02T10:36:46.079597Z"},"id":"2f94n6S-6YCO"},"outputs":[],"source":["# location of train and test files\n","train_file = data_folder /'train.csv'\n","test_file = data_folder /'test.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:46.777569Z","iopub.status.busy":"2022-10-02T10:36:46.777352Z","iopub.status.idle":"2022-10-02T10:36:47.156034Z","shell.execute_reply":"2022-10-02T10:36:47.155560Z","shell.execute_reply.started":"2022-10-02T10:36:46.777555Z"},"id":"5ggR-K3o6fhY"},"outputs":[],"source":["# creating Pandas Dataframe\n","train_data = pd.read_csv(train_file, index_col=0)\n","test_data = pd.read_csv(test_file, index_col=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T10:36:47.779375Z","iopub.status.busy":"2022-10-02T10:36:47.779163Z","iopub.status.idle":"2022-10-02T10:36:47.804926Z","shell.execute_reply":"2022-10-02T10:36:47.804508Z","shell.execute_reply.started":"2022-10-02T10:36:47.779361Z"},"executionInfo":{"elapsed":106,"status":"ok","timestamp":1665370877459,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"RXYsyw4r7OGb","outputId":"a3d881d9-309e-44d7-8ff5-dcaa09153c3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of Training data set is : (25000, 2)\n","Shape of Test data set is : (25000, 2)\n"]}],"source":["# print shape of the datasets\n","print(f'Shape of Training data set is : {train_data.shape}')\n","print(f'Shape of Test data set is : {test_data.shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"execution":{"iopub.execute_input":"2022-10-02T10:36:52.169775Z","iopub.status.busy":"2022-10-02T10:36:52.169490Z","iopub.status.idle":"2022-10-02T10:36:52.197634Z","shell.execute_reply":"2022-10-02T10:36:52.197211Z","shell.execute_reply.started":"2022-10-02T10:36:52.169761Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665370877459,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"ETuO1KJp7R8W","outputId":"b2d0cadb-c09f-413b-bb82-a299a68ae85f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             Reviews  Labels\n","0  Ever wanted to know just how much Hollywood co...       1\n","1  The movie itself was ok for the kids. But I go...       1\n","2  You could stage a version of Charles Dickens' ...       1\n","3  this was a fantastic episode. i saw a clip fro...       1\n","4  and laugh out loud funny in many scenes.<br />...       1"],"text/html":["\n","  <div id=\"df-f6753d15-9a1a-4df8-89c6-65b15be029b1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Reviews</th>\n","      <th>Labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ever wanted to know just how much Hollywood co...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The movie itself was ok for the kids. But I go...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>You could stage a version of Charles Dickens' ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>this was a fantastic episode. i saw a clip fro...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>and laugh out loud funny in many scenes.&lt;br /&gt;...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6753d15-9a1a-4df8-89c6-65b15be029b1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f6753d15-9a1a-4df8-89c6-65b15be029b1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f6753d15-9a1a-4df8-89c6-65b15be029b1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}],"source":["train_data.head()"]},{"cell_type":"markdown","metadata":{"id":"bTrbf15aROgj"},"source":["## <Font color = 'pickle'>**Create Train/Test/Valid Split**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:53.741135Z","iopub.status.busy":"2022-10-02T10:36:53.740895Z","iopub.status.idle":"2022-10-02T10:36:53.765434Z","shell.execute_reply":"2022-10-02T10:36:53.765032Z","shell.execute_reply.started":"2022-10-02T10:36:53.741117Z"},"id":"9RFTtWvX7Vwr"},"outputs":[],"source":["X, y = train_data['Reviews'].values, train_data['Labels'].values"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:54.579916Z","iopub.status.busy":"2022-10-02T10:36:54.579740Z","iopub.status.idle":"2022-10-02T10:36:54.605722Z","shell.execute_reply":"2022-10-02T10:36:54.605282Z","shell.execute_reply.started":"2022-10-02T10:36:54.579903Z"},"id":"a8sZ605P7mON"},"outputs":[],"source":["X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.20, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:55.365747Z","iopub.status.busy":"2022-10-02T10:36:55.365469Z","iopub.status.idle":"2022-10-02T10:36:55.390447Z","shell.execute_reply":"2022-10-02T10:36:55.390048Z","shell.execute_reply.started":"2022-10-02T10:36:55.365732Z"},"id":"AMapwMp88dBO"},"outputs":[],"source":["X_test , y_test = test_data['Reviews'].values, test_data['Labels'].values"]},{"cell_type":"markdown","metadata":{"id":"yNsbSCsHQkrS"},"source":["## <Font color = 'pickle'>**Data PreProcessing**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:39:45.327967Z","iopub.status.busy":"2022-10-02T10:39:45.327760Z","iopub.status.idle":"2022-10-02T10:42:41.127740Z","shell.execute_reply":"2022-10-02T10:42:41.127192Z","shell.execute_reply.started":"2022-10-02T10:39:45.327953Z"},"id":"GlDJV1QlqZPO"},"outputs":[],"source":["# X_train_cleaned = cp.SpacyPreprocessor(model = 'en_core_web_sm', batch_size=1000).transform(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:42:41.128992Z","iopub.status.busy":"2022-10-02T10:42:41.128816Z","iopub.status.idle":"2022-10-02T10:46:58.696982Z","shell.execute_reply":"2022-10-02T10:46:58.696446Z","shell.execute_reply.started":"2022-10-02T10:42:41.128979Z"},"id":"O30W-TXUsVIc"},"outputs":[],"source":["# X_valid_cleaned = cp.SpacyPreprocessor(model = 'en_core_web_sm', batch_size=1000).transform(X_valid)\n","# X_test_cleaned = cp.SpacyPreprocessor(model = 'en_core_web_sm', batch_size=1000).transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:46:58.697995Z","iopub.status.busy":"2022-10-02T10:46:58.697823Z","iopub.status.idle":"2022-10-02T10:46:58.720091Z","shell.execute_reply":"2022-10-02T10:46:58.719642Z","shell.execute_reply.started":"2022-10-02T10:46:58.697982Z"},"id":"4PBmReT_skM_"},"outputs":[],"source":["X_train_cleaned_file = data_folder / 'x_train_cleaned_bag_of_words.pkl'\n","X_valid_cleaned_file = data_folder / 'x_valid_cleaned_bag_of_words..pkl'\n","X_test_cleaned_file = data_folder / 'x_test_cleaned_bag_of_words..pkl'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:46:58.721114Z","iopub.status.busy":"2022-10-02T10:46:58.720953Z","iopub.status.idle":"2022-10-02T10:46:58.900841Z","shell.execute_reply":"2022-10-02T10:46:58.900393Z","shell.execute_reply.started":"2022-10-02T10:46:58.721101Z"},"id":"nK83ovH1s2jB"},"outputs":[],"source":["# joblib.dump(X_train_cleaned, X_train_cleaned_file)\n","# joblib.dump(X_valid_cleaned, X_valid_cleaned_file)\n","# joblib.dump(X_test_cleaned, X_test_cleaned_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:46:58.901490Z","iopub.status.busy":"2022-10-02T10:46:58.901353Z","iopub.status.idle":"2022-10-02T10:46:59.008992Z","shell.execute_reply":"2022-10-02T10:46:59.008412Z","shell.execute_reply.started":"2022-10-02T10:46:58.901477Z"},"id":"WVjfU8JUvDz5"},"outputs":[],"source":["X_train_cleaned = joblib.load(X_train_cleaned_file)\n","X_valid_cleaned = joblib.load(X_valid_cleaned_file)\n","X_test_cleaned = joblib.load(X_test_cleaned_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:46:59.009604Z","iopub.status.busy":"2022-10-02T10:46:59.009469Z","iopub.status.idle":"2022-10-02T10:47:03.292582Z","shell.execute_reply":"2022-10-02T10:47:03.292024Z","shell.execute_reply.started":"2022-10-02T10:46:59.009591Z"},"id":"xx0-0QP48kCH","executionInfo":{"status":"ok","timestamp":1665370878887,"user_tz":300,"elapsed":3,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"767382b1-a5e5-4870-dbc7-c1b299131379"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n","<class 'numpy.ndarray'>\n"]}],"source":["print(type(X_train_cleaned))\n","print(type(y_train))"]},{"cell_type":"markdown","metadata":{"id":"FTIKaTsTgvYu"},"source":["## <Font color = 'pickle'>**Custom Dataset Class**"]},{"cell_type":"code","source":["class CustomDataset(torch.utils.data.Dataset):\n","    \"\"\"IMDB dataset.\"\"\"\n","\n","    def __init__(self, X, y):\n","        self.X = np.array(X)\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        text = self.X[idx]\n","        labels = self.y[idx]\n","        sample = (text, labels)\n","        \n","        return sample"],"metadata":{"id":"kul5dyeM2d4k"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:48:16.574587Z","iopub.status.busy":"2022-10-02T10:48:16.573804Z","iopub.status.idle":"2022-10-02T10:48:16.598997Z","shell.execute_reply":"2022-10-02T10:48:16.598555Z","shell.execute_reply.started":"2022-10-02T10:48:16.574571Z"},"id":"R1mKoKSlAxAq"},"outputs":[],"source":["trainset = CustomDataset(X_train_cleaned,y_train)\n","validset = CustomDataset(X_valid_cleaned,y_valid)\n","testset = CustomDataset(X_test_cleaned,y_test)"]},{"cell_type":"markdown","metadata":{"id":"XoEVe7eGtY7U"},"source":["## <Font color = 'pickle'>**Create Vocab**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LRLHO-M1to6q"},"outputs":[],"source":["def create_vocab(dataset, min_freq):\n","  counter = Counter()\n","  for (text, _) in dataset:\n","    counter.update(str(text).split())\n","  my_vocab = vocab(counter, min_freq=min_freq)\n","  my_vocab.insert_token('<unk>', 0)\n","  my_vocab.set_default_index(0)\n","  return my_vocab"]},{"cell_type":"markdown","source":["vocab should always be created based on trainset"],"metadata":{"id":"TY5oKhQlJPQL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wNUi_aNctkAo"},"outputs":[],"source":["imdb_vocab = create_vocab(trainset, min_freq = 2)"]},{"cell_type":"code","source":["len(imdb_vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ask8H1QJJMZK","executionInfo":{"status":"ok","timestamp":1665370895873,"user_tz":300,"elapsed":6,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"11e3e9db-381d-4ce4-d4df-b2a7c39e5509"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["36241"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":136,"status":"ok","timestamp":1665370896301,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"eyaeFqCsuRTQ","jupyter":{"outputs_hidden":true},"outputId":"4cdba777-668f-4b23-e447-963f29861d29","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<unk>', 'production', 'absolutely', 'storyline', 'acting']"]},"metadata":{},"execution_count":27}],"source":["imdb_vocab.get_itos()[0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WDMu8-JOujxY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665367504070,"user_tz":300,"elapsed":3,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"d98a6891-8ae3-4d0b-82ff-6ac201ab6a71"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":32}],"source":["imdb_vocab['abracadabra']"]},{"cell_type":"markdown","metadata":{"id":"ojvSMWR5u-LU"},"source":["## <Font color = 'pickle'>**Collate_fn for Data Loaders**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cdBKJlVmvB-9"},"outputs":[],"source":["# Creating a lambda function objects that will be used to get the indices of words from vocab\n","text_pipeline = lambda x: [imdb_vocab[token] for token in str(x).split()]\n","label_pipeline = lambda x: int(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cL1TZVthvIT2"},"outputs":[],"source":["'''\n","We know that input to the embedding layers are indices of words from the vocab.\n","The collate_batch() accepts batch of data and gets the indices of text from vocab and returns the same\n","We will include this collate_batch() in collat_fn attribute of DataLoader.\n","So it will create a batch of data containing indices of words and corresponding labels.\n","But for EmbeddingBag we need one more extra parameter, that is offset.\n","offsets determines the starting index position of each bag (sequence) in input.\n","'''\n","def collate_batch(batch):\n","    label_list, text_list, offsets = [], [], [0]\n","    for (_text, _label) in batch:\n","         label_list.append(label_pipeline(_label))\n","         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n","         text_list.append(processed_text)\n","         offsets.append(processed_text.size(0))\n","    label_list = torch.tensor(label_list, dtype=torch.int64)\n","    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n","    text_list = torch.cat(text_list)\n","    return text_list, label_list, offsets"]},{"cell_type":"markdown","metadata":{"id":"U5PslDp5R7Ff"},"source":["## <Font color = 'pickle'>**Check Data Loaders**\n","\n","Let us check if our collate function is working by creating a dataloader"]},{"cell_type":"code","source":["batch_size=2\n","check_loader= torch.utils.data.DataLoader(dataset=trainset,\n","                                        batch_size=batch_size,\n","                                        shuffle=True,\n","                                        collate_fn=collate_batch,\n","                                        num_workers=4)"],"metadata":{"id":"4ltYqq5e4NLD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for text, label, offsets in check_loader:\n","  print(label, text, offsets)\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"logKAfqD4SXB","executionInfo":{"status":"ok","timestamp":1665370904563,"user_tz":300,"elapsed":830,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"7109dd68-754a-446d-8f59-8ee0d049f27f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 1]) tensor([  370,  2534,    39,    13,     8,  1734,   758,    13,    41,  1875,\n","           13,   126,   619,     4,  1103,   919,   307,  2992,   220,    13,\n","         1477,   746,   332,  1095, 19569,  1472,  1155,  7314,  1085,  4657,\n","         6803,  9108, 31384,    13,    11,  6930,  1004,   496,   307, 14239,\n","        31386,     0,    13,   391,   496,  1477,   501,   691, 17670,   156,\n","         1432,     2,   123,   847,  1278,  5259,  1961,   123,   154, 10375,\n","           89,   579,   102,   578,   243,  4184,  1277,     0,  3986,  1386,\n","          725,   518,  1121,   156,   307,   847,   342,   242,   243, 23138,\n","        14751,  4533,   109,  1931,  8190,  2272,   243,    66,  1317,  4922,\n","          651,  1303,   938,  1946,    34,  7640,   456,   582,    66,   969,\n","          847,  2271,  2724,  4560,  2029,  2647, 14995, 14223]) tensor([ 0, 49])\n"]}]},{"cell_type":"markdown","metadata":{"id":"iQ60WJKlg3bQ"},"source":["# <font color = 'pickle'> **Functions to implement NN Training**"]},{"cell_type":"markdown","metadata":{"id":"3D7A5cBeFoAI"},"source":["Now, we will start implementing our Softmax Regression Model from scratch.\n","\n","We will now create following functions:\n","\n","- **Model**\n","- **Loss Function** \n","- **One Hot Encoding**\n","- **Training Loop for 1 epoch**\n","- **Validation Loop for 1 epoch**\n","- **Model Training** - repeat the training and validation loops for given number of epochs\n","- **Function to get the accuracy given the model**"]},{"cell_type":"markdown","metadata":{"id":"GLIXu5RaylkZ"},"source":["## <Font color = 'pickle'>**Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:59:03.435895Z","iopub.status.busy":"2022-10-02T10:59:03.435684Z","iopub.status.idle":"2022-10-02T10:59:03.460780Z","shell.execute_reply":"2022-10-02T10:59:03.460317Z","shell.execute_reply.started":"2022-10-02T10:59:03.435881Z"},"id":"LNJY8GBipO2q","tags":[]},"outputs":[],"source":["class MLPCustom(nn.Module):\n","  def __init__(self, embed_dim, vocab_size, h_sizes_list, d_prob_list, output_dim, non_linearity, batch_norm):\n","\n","    super().__init__()\n","\n","    self.output_dim = output_dim\n","    self.vocab_size = vocab_size\n","    self.embed_dim = embed_dim\n","    self.h_sizes_list = h_sizes_list\n","    self.d_prob_list = d_prob_list\n","    self.batch_norm = batch_norm\n","    \n","    self.non_linearity = non_linearity\n","\n","    \n","\n","    model_layers = []\n","\n","    # embedding_layer\n","    self.embedding = nn.EmbeddingBag(self.vocab_size, self.embed_dim)\n","\n","    input_dim = self.embed_dim\n","    # hidden layers, droput, non_linearity, batchnorm layers\n","    for k, hidden_size in enumerate(self.h_sizes_list):\n","      # hidden_layer\n","      model_layers.append(nn.Linear(input_dim, hidden_size))\n","      # Activation function\n","      model_layers.append(self.non_linearity)\n","      # Dropout Layer\n","      model_layers.append(nn.Dropout(p=self.d_prob_list[k]))\n","      # Batch_Norm Layer\n","      if self.batch_norm:\n","        model_layers.append(nn.BatchNorm1d(hidden_size, momentum = 0.9))\n","      input_dim = hidden_size\n","\n","    # output layer  \n","    model_layers.append(nn.Linear(self.h_sizes_list[-1], self.output_dim))\n","\n","    self.module_list = nn.ModuleList(model_layers)\n","    \n","\n","  def forward(self, x, offsets):\n","    out = self.embedding(x, offsets) # batchsize, embedding_dim\n","    for layer in self.module_list:\n","      out = layer(out)\n","    return out\n","\n","    # Note : We do not need to apply softmax as we will be using nn.CrossEntropy Loss"]},{"cell_type":"markdown","metadata":{"id":"aqI_o6qwy6lb"},"source":["## <Font color = 'pickle'>**Function for Training  Loops**\n","\n","**Model Training** involves five steps: \n","\n","- Step 0: Randomly initialize parameters / weights\n","- Step 1: Compute model's predictions - forward pass\n","- Step 2: Compute loss\n","- Step 3: Compute the gradients\n","- Step 4: Update the parameters\n","- Step 5: Repeat steps 1 - 4\n","\n","Model training is repeating this process over and over, for many **epochs**.\n","\n","We will specify number of ***epochs*** and during each epoch we will iterate over the complete dataset and will keep on updating the parameters.\n","\n","***Learning rate*** and ***epochs*** are known as hyperparameters. We have to adjust the values of these two based on validation dataset.\n","\n","We will now create functions for step 1 to 4."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T05:14:37.034571Z","iopub.status.busy":"2022-09-14T05:14:37.034212Z","iopub.status.idle":"2022-09-14T05:14:37.040441Z","shell.execute_reply":"2022-09-14T05:14:37.039923Z","shell.execute_reply.started":"2022-09-14T05:14:37.034554Z"},"id":"Pv4x22lZMn5p","tags":[]},"outputs":[],"source":["def train(train_loader, loss_function, model, optimizer, grad_clipping, max_norm, log_batch, log_interval):\n","\n","  # Training Loop \n","\n","  # initilalize variables as global\n","  # these counts will be updated every epoch\n","  global batch_ct_train\n","\n","  # Initialize train_loss at the he start of the epoch\n","  running_train_loss = 0\n","  running_train_correct = 0\n","  \n","  # put the model in training mode\n","\n","  model.train()\n","  # Iterate on batches from the dataset using train_loader\n","  for input_, targets, offsets in train_loader:\n","    \n","    # move inputs and outputs to GPUs\n","    input_ = input_.to(device)\n","    targets = targets.to(device)\n","    offsets = offsets.to(device)\n","\n","\n","    # Step 1: Forward Pass: Compute model's predictions \n","    output = model(input_, offsets)\n","    \n","    # Step 2: Compute loss\n","    loss = loss_function(output, targets)\n","\n","    # Correct prediction\n","    y_pred = torch.argmax(output, dim = 1)\n","    correct = torch.sum(y_pred == targets)\n","\n","    batch_ct_train += 1\n","\n","    # Step 3: Backward pass -Compute the gradients\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    # Gradient Clipping\n","    if grad_clipping:\n","      nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm, norm_type=2)\n","\n","    # Step 4: Update the parameters\n","    optimizer.step()\n","          \n","    # Add train loss of a batch \n","    running_train_loss += loss.item()\n","\n","    # Add Corect counts of a batch\n","    running_train_correct += correct\n","\n","    # log batch loss and accuracy\n","    if log_batch:\n","      if ((batch_ct_train + 1) % log_interval) == 0:\n","        wandb.log({f\"Train Batch Loss  :\": loss})\n","        wandb.log({f\"Train Batch Acc :\": correct/len(targets)})\n","\n","  \n","  # Calculate mean train loss for the whole dataset for a particular epoch\n","  train_loss = running_train_loss/len(train_loader)\n","\n","  # Calculate accuracy for the whole dataset for a particular epoch\n","  train_acc = running_train_correct/len(train_loader.dataset)\n","  \n","\n","  return train_loss, train_acc"]},{"cell_type":"markdown","metadata":{"id":"KeLm-GI5bW2V"},"source":["## <Font color = 'pickle'>**Function for Validation Loops**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T05:14:37.041486Z","iopub.status.busy":"2022-09-14T05:14:37.041103Z","iopub.status.idle":"2022-09-14T05:14:37.045892Z","shell.execute_reply":"2022-09-14T05:14:37.045411Z","shell.execute_reply.started":"2022-09-14T05:14:37.041468Z"},"id":"pHP1WKDessiI","tags":[]},"outputs":[],"source":["def validate(valid_loader, loss_function, model, log_batch, log_interval):\n","\n","  # initilalize variables as global\n","  # these counts will be updated every epoch\n","  global batch_ct_valid\n","\n","  # Validation/Test loop\n","  # Initialize valid_loss at the he strat of the epoch\n","  running_val_loss = 0\n","  running_val_correct = 0\n","\n","  # put the model in evaluation mode\n","  model.eval()\n","\n","  with torch.no_grad():\n","    for input_, targets, offsets in valid_loader:\n","\n","      # move inputs and outputs to GPUs\n","      input_ = input_.to(device)\n","      targets = targets.to(device)\n","      offsets = offsets.to(device)\n","\n","      # Step 1: Forward Pass: Compute model's predictions \n","      output = model(input_, offsets)\n","\n","      # Step 2: Compute loss\n","      loss = loss_function(output, targets)\n","\n","      # Correct Predictions\n","      y_pred = torch.argmax(output, dim = 1)\n","      correct = torch.sum(y_pred == targets)\n","\n","      batch_ct_valid += 1\n","\n","      # Add val loss of a batch \n","      running_val_loss += loss.item()\n","\n","      # Add correct count for each batch\n","      running_val_correct += correct\n","\n","      # log batch loss and accuracy\n","      if log_batch:\n","        if ((batch_ct_valid + 1) % log_interval) == 0:\n","          wandb.log({f\"Valid Batch Loss  :\": loss})\n","          wandb.log({f\"Valid Batch Accuracy :\": correct/len(targets)})\n","\n","    # Calculate mean val loss for the whole dataset for a particular epoch\n","    val_loss = running_val_loss/len(valid_loader)\n","\n","    # Calculate accuracy for the whole dataset for a particular epoch\n","    val_acc = running_val_correct/len(valid_loader.dataset)\n","\n","    # scheduler step\n","    # scheduler.step(valid_loss)\n","    # scheduler.step()\n","    \n","  return val_loss, val_acc"]},{"cell_type":"markdown","metadata":{"id":"UwF70eqE6n_v"},"source":["## <Font color = 'pickle'>**Function for Model Training**\n","    \n","We will now create a function for step 5 of model training\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T05:14:37.046765Z","iopub.status.busy":"2022-09-14T05:14:37.046539Z","iopub.status.idle":"2022-09-14T05:14:37.052365Z","shell.execute_reply":"2022-09-14T05:14:37.051881Z","shell.execute_reply.started":"2022-09-14T05:14:37.046748Z"},"id":"KeCKVgg-5FiZ","tags":[]},"outputs":[],"source":["def train_loop(train_loader, valid_loader, model, optimizer, loss_function, epochs, device, patience, early_stopping,\n","               file_model):\n","    \n","  \"\"\" \n","  Function for training the model and plotting the graph for train & validation loss vs epoch.\n","  Input: iterator for train dataset, initial weights and bias, epochs, learning rate, batch size.\n","  Output: final weights, bias and train loss and validation loss for each epoch.\n","  \"\"\"\n","\n","  # Create lists to store train and val loss at each epoch\n","  train_loss_history = []\n","  valid_loss_history = []\n","  train_acc_history = []\n","  valid_acc_history = []\n","\n","  # initialize variables for early stopping\n","\n","  delta = 0\n","  best_score = None\n","  valid_loss_min = np.Inf\n","  counter_early_stop=0\n","  early_stop=False\n","\n","  # Iterate for the given number of epochs\n","  # Step 5: Repeat steps 1 - 4\n","\n","  for epoch in range(epochs):\n","\n","    t0 = datetime.now()\n","\n","    # Get train loss and accuracy for one epoch\n","    train_loss, train_acc = train(train_loader, loss_function, model, optimizer, \n","                                  wandb.config.GRAD_CLIPPING, wandb.config.MAX_NORM,\n","                                  wandb.config.LOG_BATCH, wandb.config.LOG_INTERVAL)\n","    valid_loss, valid_acc   = validate(valid_loader, loss_function, model, \n","                                       wandb.config.LOG_BATCH, wandb.config.LOG_INTERVAL)\n","\n","    dt = datetime.now() - t0\n","\n","    # Save history of the Losses and accuracy\n","    train_loss_history.append(train_loss)\n","    train_acc_history.append(train_acc)\n","\n","    valid_loss_history.append(valid_loss)\n","    valid_acc_history.append(valid_acc)\n","\n","    # Log the train and valid loss to wandb\n","    wandb.log({f\"Train Loss :\": train_loss, \"epoch\": epoch})\n","    wandb.log({f\"Train Acc :\": train_acc, \"epoch\": epoch})\n","\n","    wandb.log({f\"Valid Loss :\": valid_loss, \"epoch\": epoch})\n","    wandb.log({f\"Valid Acc :\": valid_acc, \"epoch\": epoch})\n","\n","    if early_stopping:\n","      score = -valid_loss\n","      if best_score is None:\n","        best_score=score\n","        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n","        torch.save(model.state_dict(), file_model)\n","        valid_loss_min = valid_loss\n","\n","      elif score < best_score + delta:\n","        counter_early_stop += 1\n","        print(f'Early stoping counter: {counter_early_stop} out of {patience}')\n","        if counter_early_stop > patience:\n","          early_stop = True\n","\n","\n","      else:\n","        best_score = score\n","        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n","        torch.save(model.state_dict(), file_model)\n","        counter_early_stop=0\n","        valid_loss_min = valid_loss\n","\n","      if early_stop:\n","        print('Early Stopping')\n","        break\n","\n","    else:\n","\n","      score = -valid_loss\n","      if best_score is None:\n","        best_score=score\n","        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n","        torch.save(model.state_dict(), file_model)\n","        valid_loss_min = valid_loss\n","\n","      elif score < best_score + delta:\n","        print(f'Validation loss has not decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Not Saving Model...')\n","      \n","      else:\n","        best_score = score\n","        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n","        torch.save(model.state_dict(), file_model)\n","        valid_loss_min = valid_loss\n","    \n","    # Print the train loss and accuracy for given number of epochs, batch size and number of samples\n","    print(f'Epoch : {epoch+1} / {epochs}')\n","    print(f'Time to complete {epoch+1} is {dt}')\n","    # print(f'Learning rate: {scheduler._last_lr[0]}')\n","    print(f'Train Loss: {train_loss : .4f} | Train Accuracy: {train_acc * 100 : .4f}%')\n","    print(f'Valid Loss: {valid_loss : .4f} | Valid Accuracy: {valid_acc * 100 : .4f}%')\n","    print()\n","    torch.cuda.empty_cache()\n","\n","  return train_loss_history, train_acc_history, valid_loss_history, valid_acc_history"]},{"cell_type":"markdown","metadata":{"id":"FWCLH47azD6j"},"source":["## <Font color = 'pickle'>**Function for Accuracy and Predictions**\n","\n","Now we have final values for weights and bias after training the model. We will use these values to make predictions on the test dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T05:14:37.053263Z","iopub.status.busy":"2022-09-14T05:14:37.052958Z","iopub.status.idle":"2022-09-14T05:14:37.057864Z","shell.execute_reply":"2022-09-14T05:14:37.057274Z","shell.execute_reply.started":"2022-09-14T05:14:37.053246Z"},"id":"M6KZqsnqQFVu","tags":[]},"outputs":[],"source":["def get_acc_pred(data_loader, model, device):\n","    \n","  \"\"\" \n","  Function to get predictions and accuracy for a given data using estimated model\n","  Input: Data iterator, Final estimated weoights, bias\n","  Output: Prections and Accuracy for given dataset\n","  \"\"\"\n","\n","  # Array to store predicted labels\n","  predictions = torch.Tensor() # empty tensor\n","  predictions = predictions.to(device) # move predictions to GPU\n","\n","  # Array to store actual labels\n","  y = torch.Tensor() # empty tensor\n","  y = y.to(device)\n","\n","  # put the model in evaluation mode\n","  model.eval()\n","  \n","  # Iterate over batches from data iterator\n","  with torch.no_grad():\n","    for input_, targets, offsets in data_loader:\n","      \n","      # move inputs and outputs to GPUs\n","      \n","      input_ = input_.to(device)\n","      targets = targets.to(device)\n","      offsets = offsets.to(device)\n","      \n","      # Calculated the predicted labels\n","      output = model(input_, offsets)\n","\n","      # Choose the label with maximum probability\n","      prediction = torch.argmax(output, dim = 1)\n","\n","      # Add the predicted labels to the array\n","      predictions = torch.cat((predictions, prediction)) \n","\n","      # Add the actual labels to the array\n","      y = torch.cat((y, targets)) \n","\n","  # Check for complete dataset if actual and predicted labels are same or not\n","  # Calculate accuracy\n","  acc = (predictions == y).float().mean()\n","\n","  # Return tuple containing predictions and accuracy\n","  return predictions, acc  "]},{"cell_type":"markdown","source":["# <Font color = 'pickle'>**Meta Data**"],"metadata":{"id":"5nF5iTy_VqdV"}},{"cell_type":"code","source":["hyperparameters = SimpleNamespace(\n","    EMBED_DIM = 300,\n","    VOCAB_SIZE = len(imdb_vocab),\n","    OUTPUT_DIM = 2,\n","    HIDDEN_SIZES_LIST = [200, 100], # 100 layers of size 200  [200]*100\n","    DPROB_LIST = [0.5, 0.5],\n","    NON_LINEARITY= nn.ReLU(),\n","    BATCH_NORM = False,\n","    EPOCHS = 50,\n","    \n","    BATCH_SIZE = 128,\n","    LEARNING_RATE = 0.001,\n","    DATASET=\"IMDB\",\n","    ARCHITECTUREe=\"Embed_2_hidden_layers\",\n","    LOG_INTERVAL = 25,\n","    LOG_BATCH = True,\n","    FILE_MODEL = model_folder/'imdb_2_hidden_layers.pt',\n","    GRAD_CLIPPING = False,\n","    MAX_NORM = 0,\n","    MOMENTUM = 0,\n","    PATIENCE = 5,\n","    EARLY_STOPPING = True,\n","    # SCHEDULER_FACTOR = 0,\n","    # SCHEDULER_PATIENCE = 0,\n","    WEIGHT_DECAY = 0.001\n","    )"],"metadata":{"id":"TAuG3mxBWHaz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oVk_RctgdPRP"},"source":["# <Font color = 'pickle'>**Data Loaders, Loss Function, Optimizer**"]},{"cell_type":"code","source":["# Initialize a new project\n","import random\n","wandb.init(name = 'Embed_2_hidden_layers', project = 'NLP_MLP_imdb')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":196},"id":"3kCRNDlu-zbE","executionInfo":{"status":"ok","timestamp":1665373707247,"user_tz":300,"elapsed":4468,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"1545aeab-c0a9-4107-d274-03137cfb9c35"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:14umm2sm) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">Embed_2_hidden_layers</strong>: <a href=\"https://wandb.ai/hsingh-utd/NLP_MLP_imdb/runs/14umm2sm\" target=\"_blank\">https://wandb.ai/hsingh-utd/NLP_MLP_imdb/runs/14umm2sm</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221010_033117-14umm2sm/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:14umm2sm). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.4"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20221010_034822-1e43031j</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/hsingh-utd/NLP_MLP_imdb/runs/1e43031j\" target=\"_blank\">Embed_2_hidden_layers</a></strong> to <a href=\"https://wandb.ai/hsingh-utd/NLP_MLP_imdb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/hsingh-utd/NLP_MLP_imdb/runs/1e43031j?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f5aebe53890>"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["wandb.config = hyperparameters\n","wandb.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gnl8vsAN-5Tq","executionInfo":{"status":"ok","timestamp":1665373707247,"user_tz":300,"elapsed":3,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"fe38e140-cf8d-4888-f887-9c539d57d97b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["namespace(ARCHITECTUREe='Embed_2_hidden_layers', BATCH_NORM=False, BATCH_SIZE=128, DATASET='IMDB', DPROB_LIST=[0.5, 0.5], EARLY_STOPPING=True, EMBED_DIM=300, EPOCHS=50, FILE_MODEL=PosixPath('/content/drive/MyDrive/data/models/nlp_fall_2022/imdb/imdb_2_hidden_layers.pt'), GRAD_CLIPPING=False, HIDDEN_SIZES_LIST=[200, 100], LEARNING_RATE=0.001, LOG_BATCH=True, LOG_INTERVAL=25, MAX_NORM=0, MOMENTUM=0, NON_LINEARITY=ReLU(), OUTPUT_DIM=2, PATIENCE=5, VOCAB_SIZE=36241, WEIGHT_DECAY=0.001)"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:18:45.004101Z","iopub.status.busy":"2022-10-02T11:18:45.003880Z","iopub.status.idle":"2022-10-02T11:18:55.147743Z","shell.execute_reply":"2022-10-02T11:18:55.147122Z","shell.execute_reply.started":"2022-10-02T11:18:45.004087Z"},"id":"fZ6ZoM9WaS_M","tags":[]},"outputs":[],"source":["# Fix seed value\n","SEED = 2345\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","# Data Loader\n","train_loader = torch.utils.data.DataLoader(trainset, batch_size=wandb.config.BATCH_SIZE, shuffle = True, \n","                                           collate_fn=collate_batch, num_workers = 4)\n","valid_loader = torch.utils.data.DataLoader(validset, batch_size=wandb.config.BATCH_SIZE, shuffle = False, \n","                                           collate_fn=collate_batch,  num_workers = 4)\n","test_loader = torch.utils.data.DataLoader(testset, batch_size=wandb.config.BATCH_SIZE,   shuffle = False, \n","                                          collate_fn=collate_batch,  num_workers = 4)\n","\n","# cross entropy loss function\n","loss_function = nn.CrossEntropyLoss()\n","\n","# use GPUs\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","wandb.config.DEVICE = device\n","\n","# model \n","model_imdb = MLPCustom(wandb.config.EMBED_DIM, \n","                       wandb.config.VOCAB_SIZE, \n","                       wandb.config.HIDDEN_SIZES_LIST, \n","                       wandb.config.DPROB_LIST,\n","                       wandb.config.OUTPUT_DIM, \n","                       wandb.config.NON_LINEARITY,\n","                       wandb.config.BATCH_NORM)\n","\n","model_imdb.to(wandb.config.DEVICE)\n","\n","def init_weights(m):\n","  if type(m) == nn.Linear:\n","      torch.nn.init.kaiming_normal_(m.weight)\n","      torch.nn.init.zeros_(m.bias)\n","        \n","# apply initialization recursively  to all modules\n","model_imdb.apply(init_weights)\n","\n","# Intialize stochiastic gradient descent optimizer\n","optimizer = torch.optim.Adam(model_imdb.parameters(), \n","                             lr = wandb.config.LEARNING_RATE, \n","                             weight_decay=wandb.config.WEIGHT_DECAY)\n","\n","# wandb.config.OPTIMIZER = optimizer\n","\n","# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor= wandb.config.scheduler_factor, \n","#                              patience=wandb.config.scheduler_patience, verbose=True)\n","\n","#scheduler = StepLR(optimizer, gamma=0.4,step_size=1, verbose=True)"]},{"cell_type":"code","source":["wandb.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6etbfbQkm-zv","executionInfo":{"status":"ok","timestamp":1665373714027,"user_tz":300,"elapsed":283,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"d8a30778-2fa1-4285-f76f-86257efe429b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["namespace(ARCHITECTUREe='Embed_2_hidden_layers', BATCH_NORM=False, BATCH_SIZE=128, DATASET='IMDB', DEVICE=device(type='cuda', index=0), DPROB_LIST=[0.5, 0.5], EARLY_STOPPING=True, EMBED_DIM=300, EPOCHS=50, FILE_MODEL=PosixPath('/content/drive/MyDrive/data/models/nlp_fall_2022/imdb/imdb_2_hidden_layers.pt'), GRAD_CLIPPING=False, HIDDEN_SIZES_LIST=[200, 100], LEARNING_RATE=0.001, LOG_BATCH=True, LOG_INTERVAL=25, MAX_NORM=0, MOMENTUM=0, NON_LINEARITY=ReLU(), OUTPUT_DIM=2, PATIENCE=5, VOCAB_SIZE=36241, WEIGHT_DECAY=0.001)"]},"metadata":{},"execution_count":69}]},{"cell_type":"markdown","source":["# <Font color = 'pickle'>**Sanity Check**\n","- Check the loss without any training. For Cross entropy the expected value will be log(number of classes)"],"metadata":{"id":"ffeGh2dcukdK"}},{"cell_type":"code","source":["for input_, targets, offsets in train_loader:\n","  \n","  # move inputs and outputs to GPUs\n","  input_ = input_.to(device)\n","  targets = targets.to(device)\n","  offsets = offsets.to(device)\n","  model_imdb.eval()\n","  # Forward pass\n","  output = model_imdb(input_, offsets)\n","  loss = loss_function(output, targets)\n","  print(f'Actual loss: {loss}')\n","  break\n","\n","print(f'Expected Theoretical loss: {np.log(2)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p2Gx7jgbumux","executionInfo":{"status":"ok","timestamp":1665373951224,"user_tz":300,"elapsed":2964,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"55ddbe3d-575e-4a45-c232-bf354f91dfb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Actual loss: 0.7161328196525574\n","Expected Theoretical loss: 0.6931471805599453\n"]}]},{"cell_type":"markdown","metadata":{"id":"e0_zWk0Ib74K"},"source":["# <Font color = 'pickle'>**Training Model**"]},{"cell_type":"code","source":["wandb.watch(model_imdb, log = 'all', log_freq=25, log_graph=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KczRQvKwiH_y","executionInfo":{"status":"ok","timestamp":1665373956373,"user_tz":300,"elapsed":242,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"23088554-6f9e-4d33-cfe6-aeb4e9eb4b43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"]},{"output_type":"execute_result","data":{"text/plain":["[<wandb.wandb_torch.TorchGraph at 0x7f5aeb594ad0>]"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:18:59.063373Z","iopub.status.busy":"2022-10-02T11:18:59.063161Z","iopub.status.idle":"2022-10-02T11:19:10.388677Z","shell.execute_reply":"2022-10-02T11:19:10.388079Z","shell.execute_reply.started":"2022-10-02T11:18:59.063359Z"},"id":"LckLb_9bhZDw","tags":[]},"outputs":[],"source":["# See live graphs in the notebook.\n","#%%wandb \n","batch_ct_train, batch_ct_valid = 0, 0\n","train_loss_history, train_acc_history, valid_loss_history, valid_acc_history = train_loop(train_loader, \n","                                                                                          valid_loader, \n","                                                                                          model_imdb, \n","                                                                                          optimizer,\n","                                                                                          loss_function, \n","                                                                                          wandb.config.EPOCHS, \n","                                                                                          wandb.config.DEVICE,\n","                                                                                          wandb.config.PATIENCE, \n","                                                                                          wandb.config.EARLY_STOPPING,\n","                                                                                          wandb.config.FILE_MODEL)"]},{"cell_type":"markdown","metadata":{"id":"c-Cj1f2Qb74K"},"source":["# <Font color = 'pickle'>**Get Accuracy, Predictions**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T11:19:29.297644Z","iopub.status.busy":"2022-10-02T11:19:29.297419Z","iopub.status.idle":"2022-10-02T11:19:29.322096Z","shell.execute_reply":"2022-10-02T11:19:29.321716Z","shell.execute_reply.started":"2022-10-02T11:19:29.297629Z"},"executionInfo":{"elapsed":201,"status":"ok","timestamp":1665374075773,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"dZQF1CbgKEKd","outputId":"566b434f-e5e7-4516-8f50-3ab8927192e7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":78}],"source":["device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:19:30.196257Z","iopub.status.busy":"2022-10-02T11:19:30.196043Z","iopub.status.idle":"2022-10-02T11:19:30.449031Z","shell.execute_reply":"2022-10-02T11:19:30.448679Z","shell.execute_reply.started":"2022-10-02T11:19:30.196243Z"},"id":"yw7GhoZuRdIO","tags":[],"executionInfo":{"status":"ok","timestamp":1665374109613,"user_tz":300,"elapsed":277,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"66a8c8a3-c7fe-4a3d-e53d-e9002102ec4b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":79}],"source":["model_nn = MLPCustom(wandb.config.EMBED_DIM, \n","                       wandb.config.VOCAB_SIZE, \n","                       wandb.config.HIDDEN_SIZES_LIST, \n","                       wandb.config.DPROB_LIST,\n","                       wandb.config.OUTPUT_DIM, \n","                       wandb.config.NON_LINEARITY,\n","                       wandb.config.BATCH_NORM)\n","model_nn.to(device)\n","model_nn.load_state_dict(torch.load(wandb.config.FILE_MODEL))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:19:31.086069Z","iopub.status.busy":"2022-10-02T11:19:31.085837Z","iopub.status.idle":"2022-10-02T11:19:31.117082Z","shell.execute_reply":"2022-10-02T11:19:31.116628Z","shell.execute_reply.started":"2022-10-02T11:19:31.086054Z"},"id":"3v2z0oFcRjrF","tags":[]},"outputs":[],"source":["# Get the prediction and accuracy for the test dataseta\n","predictions_test, acc_test = get_acc_pred(test_loader, model_nn, device)\n","predictions_train, acc_train = get_acc_pred(train_loader, model_nn, device)\n","predictions_valid, acc_valid = get_acc_pred(valid_loader, model_nn, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:19:31.696329Z","iopub.status.busy":"2022-10-02T11:19:31.696121Z","iopub.status.idle":"2022-10-02T11:19:31.721995Z","shell.execute_reply":"2022-10-02T11:19:31.721442Z","shell.execute_reply.started":"2022-10-02T11:19:31.696314Z"},"id":"vcfIlMd3FKAX","tags":[],"executionInfo":{"status":"ok","timestamp":1665374117277,"user_tz":300,"elapsed":733,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fed2e1aa-46fa-4707-8f9c-2b08498e9a20"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy tensor(84.9200, device='cuda:0')\n","Train accuracy tensor(95.3350, device='cuda:0')\n","Valid accuracy tensor(88.2600, device='cuda:0')\n"]}],"source":["# Print Test Accuracy\n","print('Test accuracy', acc_test * 100)\n","print('Train accuracy', acc_train * 100)\n","print('Valid accuracy', acc_valid * 100)"]},{"cell_type":"code","source":["wandb.log({'Best_test_Acc': acc_test})\n","wandb.log({'Best_train_Acc': acc_train})\n","wandb.log({'Best_valid_Acc': acc_valid})"],"metadata":{"id":"ZXfjniBJjX3u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"caRp4G3ov5fp"},"source":["# <Font color = 'pickle'>**Confusion Matrix for Test Data**"]},{"cell_type":"markdown","metadata":{"id":"GZf0pSyQV32m"},"source":["Now, we will make some visualizations for the predictions that we obtained."]},{"cell_type":"markdown","metadata":{"id":"5sQH0GvxXnam"},"source":["We will construct a `confusion matrix` which will help us to visualize the performance of our classification model on the test dataset as we know the true values for the test data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:36:26.514609Z","iopub.status.busy":"2022-10-02T11:36:26.514407Z","iopub.status.idle":"2022-10-02T11:36:26.542565Z","shell.execute_reply":"2022-10-02T11:36:26.541979Z","shell.execute_reply.started":"2022-10-02T11:36:26.514594Z"},"id":"NaiRaPuQYYIV","tags":[]},"outputs":[],"source":["# Get an array containing actual labels\n","testing_labels = testset.y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T11:36:45.576258Z","iopub.status.busy":"2022-10-02T11:36:45.576049Z","iopub.status.idle":"2022-10-02T11:36:45.600946Z","shell.execute_reply":"2022-10-02T11:36:45.600399Z","shell.execute_reply.started":"2022-10-02T11:36:45.576245Z"},"executionInfo":{"elapsed":166,"status":"ok","timestamp":1665374129319,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"wMuZ1Yl2X47z","outputId":"b8badb5b-fe0f-4e04-ed08-7bbd8c26d9a9","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1])"]},"metadata":{},"execution_count":84}],"source":["np.unique(testing_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:37:32.039417Z","iopub.status.busy":"2022-10-02T11:37:32.039204Z","iopub.status.idle":"2022-10-02T11:37:32.325754Z","shell.execute_reply":"2022-10-02T11:37:32.325164Z","shell.execute_reply.started":"2022-10-02T11:37:32.039403Z"},"id":"lAtBZumJcuwX","tags":[]},"outputs":[],"source":["# Log a confusion matrix to W&B\n","wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(\n","                        probs = None,\n","                        y_true = testing_labels,\n","                        preds = predictions_test.to('cpu').numpy(),\n","                        class_names =['negative', 'positive'])})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":495},"execution":{"iopub.execute_input":"2022-10-02T11:37:35.481530Z","iopub.status.busy":"2022-10-02T11:37:35.481317Z","iopub.status.idle":"2022-10-02T11:37:40.670611Z","shell.execute_reply":"2022-10-02T11:37:40.670287Z","shell.execute_reply.started":"2022-10-02T11:37:35.481517Z"},"executionInfo":{"elapsed":4624,"status":"ok","timestamp":1665374136854,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"jIlsxRdPHZYa","outputId":"2267085d-f4ca-4272-f835-e260421809c0","tags":[]},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Best_test_Acc</td><td>▁</td></tr><tr><td>Best_train_Acc</td><td>▁</td></tr><tr><td>Best_valid_Acc</td><td>▁</td></tr><tr><td>Train Acc :</td><td>▁▃▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>Train Batch Acc :</td><td>▁▂▃▃▃▄▅▅▆▆▆▆▅▅▅▄▇▆▆▆▇▆▇█▇▇▇▇▆██▆▇▇▇█▇▇██</td></tr><tr><td>Train Batch Loss  :</td><td>█▇▆▇▇▅▅▅▄▄▄▄▅▅▅▆▃▃▃▃▃▃▂▂▃▃▃▂▃▁▂▂▂▂▂▁▂▂▁▂</td></tr><tr><td>Train Loss :</td><td>█▇▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Valid Acc :</td><td>▁▃▃▄▄▅▅▆▇▇▆▇▇▇▇██████████</td></tr><tr><td>Valid Batch Accuracy :</td><td>▁▄▃▄▅▄▂▃▃▆▃▅▆▅▄▅▅▆▅▇▆▆▄▆▆▇▅▇▆▇▅▆▆▇▆█▅▆▅▆</td></tr><tr><td>Valid Batch Loss  :</td><td>█▇█▇▆██▇▆▅▆▄▄▆▆▅▅▃▆▂▃▄▆▄▅▂▆▂▃▄▅▄▄▁▄▁▅▅▄▄</td></tr><tr><td>Valid Loss :</td><td>█▇▆▅▅▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best_test_Acc</td><td>0.8492</td></tr><tr><td>Best_train_Acc</td><td>0.95335</td></tr><tr><td>Best_valid_Acc</td><td>0.8826</td></tr><tr><td>Train Acc :</td><td>0.94235</td></tr><tr><td>Train Batch Acc :</td><td>0.92188</td></tr><tr><td>Train Batch Loss  :</td><td>0.20773</td></tr><tr><td>Train Loss :</td><td>0.15872</td></tr><tr><td>Valid Acc :</td><td>0.8772</td></tr><tr><td>Valid Batch Accuracy :</td><td>0.89062</td></tr><tr><td>Valid Batch Loss  :</td><td>0.30108</td></tr><tr><td>Valid Loss :</td><td>0.33729</td></tr><tr><td>epoch</td><td>24</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">Embed_2_hidden_layers</strong>: <a href=\"https://wandb.ai/hsingh-utd/NLP_MLP_imdb/runs/1e43031j\" target=\"_blank\">https://wandb.ai/hsingh-utd/NLP_MLP_imdb/runs/1e43031j</a><br/>Synced 5 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221010_034822-1e43031j/logs</code>"]},"metadata":{}}],"source":["wandb.finish()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}