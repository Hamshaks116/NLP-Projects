{"cells":[{"cell_type":"markdown","metadata":{"id":"Vl3eIEYFkgP7"},"source":["<h1 align='center'><b><font color ='pickle'>Refactor Custom Shallow NN</b></h1>\n","\n","Changes Made\n","- Use Embedding Layer instead of tfidf \n","Move dataloaders, loss functions, optimizer after wandb.init()\n","- Check transformation using check loader\n","- Training Loops\n","> Add functionality for \n",">- model.train(); model.eval()\n",">- Gradient Clipping\n",">- log batch loss and accuracy \n",">- print time it  takes to run epoch\n",">- Save checkpoints\n",">- Early stopping\n","\n","- Add Dictionary for Hyperparameters\n","- Learning Rate Scheduler\n","- Weight Decay\n","- Enhance wandb logging\n","- Add seed for reproducability\n","- Sanity Check \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FIxAU6f3S-MI"},"source":["# <Font color = 'pickle'>**Load Libraries/Install Software**"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:35:35.790529Z","iopub.status.busy":"2022-10-02T10:35:35.790311Z","iopub.status.idle":"2022-10-02T10:35:35.800037Z","shell.execute_reply":"2022-10-02T10:35:35.799579Z","shell.execute_reply.started":"2022-10-02T10:35:35.790485Z"},"id":"silZTZDXNSGU","executionInfo":{"status":"ok","timestamp":1665367470481,"user_tz":300,"elapsed":3,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T10:35:36.754664Z","iopub.status.busy":"2022-10-02T10:35:36.754227Z","iopub.status.idle":"2022-10-02T10:35:36.760593Z","shell.execute_reply":"2022-10-02T10:35:36.760035Z","shell.execute_reply.started":"2022-10-02T10:35:36.754648Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665367470481,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"-h5a-vtFb738","outputId":"e8b1152a-c415-42ad-d0ce-1bdb8a4ae6c1","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on CoLab\n"]}],"source":["if 'google.colab' in str(get_ipython()):\n","  print('Running on CoLab')\n","else:\n","  print('Not running on CoLab')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:35:37.679455Z","iopub.status.busy":"2022-10-02T10:35:37.679286Z","iopub.status.idle":"2022-10-02T10:35:37.685382Z","shell.execute_reply":"2022-10-02T10:35:37.684911Z","shell.execute_reply.started":"2022-10-02T10:35:37.679443Z"},"executionInfo":{"elapsed":4211,"status":"ok","timestamp":1665367474690,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"q4OpOEo0QktF","tags":[]},"outputs":[],"source":["# Install wandb and update it to the latest version\n","if 'google.colab' in str(get_ipython()):\n","    !pip install wandb --upgrade -q"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T10:35:38.966991Z","iopub.status.busy":"2022-10-02T10:35:38.966806Z","iopub.status.idle":"2022-10-02T10:35:38.974840Z","shell.execute_reply":"2022-10-02T10:35:38.974410Z","shell.execute_reply.started":"2022-10-02T10:35:38.966978Z"},"executionInfo":{"elapsed":1230,"status":"ok","timestamp":1665367475917,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"m7C0tvyKoy6f","outputId":"8d2fcf1f-cd9c-40d5-a4f3-10138b857a55","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# mount google drive\n","if 'google.colab' in str(get_ipython()):\n","    from google.colab import drive\n","    drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:35:51.980836Z","iopub.status.busy":"2022-10-02T10:35:51.980539Z","iopub.status.idle":"2022-10-02T10:35:52.005949Z","shell.execute_reply":"2022-10-02T10:35:52.005549Z","shell.execute_reply.started":"2022-10-02T10:35:51.980815Z"},"id":"TqYqOtp5yluv","tags":[],"executionInfo":{"status":"ok","timestamp":1665367477264,"user_tz":300,"elapsed":1348,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# Importing the necessary libraries\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchtext.vocab import  vocab\n","\n","import random\n","from datetime import datetime\n","import numpy as np\n","import pandas as pd\n","import joblib\n","from collections import Counter\n","from types import SimpleNamespace\n","\n","from pathlib import Path\n","import sys\n","\n","from sklearn.model_selection import train_test_split\n","import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:16.384425Z","iopub.status.busy":"2022-10-02T10:36:16.384181Z","iopub.status.idle":"2022-10-02T10:36:16.406240Z","shell.execute_reply":"2022-10-02T10:36:16.405758Z","shell.execute_reply.started":"2022-10-02T10:36:16.384410Z"},"id":"DMbfI4z8N-a9","tags":[]},"outputs":[],"source":["#if 'google.colab' in str(get_ipython()):\n","#  !python -m spacy download 'en_core_web_sm'"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T10:36:18.366715Z","iopub.status.busy":"2022-10-02T10:36:18.366492Z","iopub.status.idle":"2022-10-02T10:36:19.342975Z","shell.execute_reply":"2022-10-02T10:36:19.342550Z","shell.execute_reply.started":"2022-10-02T10:36:18.366701Z"},"executionInfo":{"elapsed":3086,"status":"ok","timestamp":1665367492399,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"vsr_hAq78XFz","outputId":"10fa3014-f050-42af-b3d4-380f5428af0b"},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhsingh-utd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}],"source":["# Login to W&B\n","wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"J2nAIo5uNxEr"},"source":["# <Font color = 'pickle'>**Specify Project Folders**"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:21.717528Z","iopub.status.busy":"2022-10-02T10:36:21.716436Z","iopub.status.idle":"2022-10-02T10:36:21.744773Z","shell.execute_reply":"2022-10-02T10:36:21.744138Z","shell.execute_reply.started":"2022-10-02T10:36:21.717511Z"},"id":"zd6c5IGa_iUl","tags":[],"executionInfo":{"status":"ok","timestamp":1665367492399,"user_tz":300,"elapsed":9,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# This is the path where we will downlaod and save data\n","if 'google.colab' in str(get_ipython()):\n","  base_folder = Path('/content/drive/MyDrive/data')\n","else:\n","  base_folder = Path('/home/harpreet/Insync/google_drive_shaannoor/data')"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:22.513975Z","iopub.status.busy":"2022-10-02T10:36:22.513801Z","iopub.status.idle":"2022-10-02T10:36:22.537843Z","shell.execute_reply":"2022-10-02T10:36:22.537305Z","shell.execute_reply.started":"2022-10-02T10:36:22.513962Z"},"id":"Z0yKILuteTDE","executionInfo":{"status":"ok","timestamp":1665367492399,"user_tz":300,"elapsed":8,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["data_folder = base_folder/'datasets/aclImdb'\n","model_folder = base_folder/'models/nlp_fall_2022/imdb'\n","custom_functions = base_folder/'custom-functions'"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:23.464470Z","iopub.status.busy":"2022-10-02T10:36:23.464298Z","iopub.status.idle":"2022-10-02T10:36:23.488166Z","shell.execute_reply":"2022-10-02T10:36:23.487795Z","shell.execute_reply.started":"2022-10-02T10:36:23.464457Z"},"id":"1i9tdWEkOha8","executionInfo":{"status":"ok","timestamp":1665367492400,"user_tz":300,"elapsed":9,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["sys.path.append(str(custom_functions))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T10:36:24.115920Z","iopub.status.busy":"2022-10-02T10:36:24.115693Z","iopub.status.idle":"2022-10-02T10:36:24.140715Z","shell.execute_reply":"2022-10-02T10:36:24.140380Z","shell.execute_reply.started":"2022-10-02T10:36:24.115905Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665367492400,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"m8C6e11FOiEX","outputId":"40209ac3-766e-4ff8-db73-0af19c572bd5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content',\n"," '/env/python',\n"," '/usr/lib/python37.zip',\n"," '/usr/lib/python3.7',\n"," '/usr/lib/python3.7/lib-dynload',\n"," '',\n"," '/usr/local/lib/python3.7/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n"," '/root/.ipython',\n"," '/content/drive/MyDrive/data/custom-functions']"]},"metadata":{},"execution_count":11}],"source":["sys.path"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:34.241275Z","iopub.status.busy":"2022-10-02T10:36:34.241066Z","iopub.status.idle":"2022-10-02T10:36:34.465547Z","shell.execute_reply":"2022-10-02T10:36:34.464959Z","shell.execute_reply.started":"2022-10-02T10:36:34.241261Z"},"id":"cw-B4qKHOjUC","executionInfo":{"status":"ok","timestamp":1665367499778,"user_tz":300,"elapsed":7385,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["import custom_preprocessor as cp"]},{"cell_type":"markdown","metadata":{"id":"17xctemopjdA"},"source":["# <Font color = 'pickle'>**IMDB Dataset**\n","\n","For this notebook, we will use IMDB movie review dataset. <br>\n","LInk for complete dataset: http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz.\n","\n","We downloaded the dataset in the previous lecture 2 notebook (notebook: 3_Faster_tokenization_spacy_final.ipynb)\n","\n","We created csv files in Lecture 2 -- train.csv and test.csv file. The files are availible in Lecture2/data folder from eLearning. I have applied the custom pre=processor and cleaned the data set for this lecture. I pickled the datasets and saved them as files. The files are available in Lecture_6/data folder. We will download the following files as well.\n","\n","- 'x_train_cleaned_bag_of_words.pkl'\n","- 'x_valid_cleaned_bag_of_words.pkl'\n","- 'x_test_cleaned_bag_of_words.pkl'"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:46.079612Z","iopub.status.busy":"2022-10-02T10:36:46.079371Z","iopub.status.idle":"2022-10-02T10:36:46.104603Z","shell.execute_reply":"2022-10-02T10:36:46.103997Z","shell.execute_reply.started":"2022-10-02T10:36:46.079597Z"},"id":"2f94n6S-6YCO","executionInfo":{"status":"ok","timestamp":1665367499779,"user_tz":300,"elapsed":7,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# location of train and test files\n","train_file = data_folder /'train.csv'\n","test_file = data_folder /'test.csv'"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:46.777569Z","iopub.status.busy":"2022-10-02T10:36:46.777352Z","iopub.status.idle":"2022-10-02T10:36:47.156034Z","shell.execute_reply":"2022-10-02T10:36:47.155560Z","shell.execute_reply.started":"2022-10-02T10:36:46.777555Z"},"id":"5ggR-K3o6fhY","executionInfo":{"status":"ok","timestamp":1665367500936,"user_tz":300,"elapsed":1164,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# creating Pandas Dataframe\n","train_data = pd.read_csv(train_file, index_col=0)\n","test_data = pd.read_csv(test_file, index_col=0)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T10:36:47.779375Z","iopub.status.busy":"2022-10-02T10:36:47.779163Z","iopub.status.idle":"2022-10-02T10:36:47.804926Z","shell.execute_reply":"2022-10-02T10:36:47.804508Z","shell.execute_reply.started":"2022-10-02T10:36:47.779361Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665367500938,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"RXYsyw4r7OGb","outputId":"5f364cc4-44f7-4c95-fc47-4ee5991943d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of Training data set is : (25000, 2)\n","Shape of Test data set is : (25000, 2)\n"]}],"source":["# print shape of the datasets\n","print(f'Shape of Training data set is : {train_data.shape}')\n","print(f'Shape of Test data set is : {test_data.shape}')"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"execution":{"iopub.execute_input":"2022-10-02T10:36:52.169775Z","iopub.status.busy":"2022-10-02T10:36:52.169490Z","iopub.status.idle":"2022-10-02T10:36:52.197634Z","shell.execute_reply":"2022-10-02T10:36:52.197211Z","shell.execute_reply.started":"2022-10-02T10:36:52.169761Z"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665367500938,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"ETuO1KJp7R8W","outputId":"b8b933b0-dbc5-4d09-de78-9105d07ad8f2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             Reviews  Labels\n","0  Ever wanted to know just how much Hollywood co...       1\n","1  The movie itself was ok for the kids. But I go...       1\n","2  You could stage a version of Charles Dickens' ...       1\n","3  this was a fantastic episode. i saw a clip fro...       1\n","4  and laugh out loud funny in many scenes.<br />...       1"],"text/html":["\n","  <div id=\"df-8bb2f13c-c731-4e9a-8446-d7101308082d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Reviews</th>\n","      <th>Labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ever wanted to know just how much Hollywood co...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The movie itself was ok for the kids. But I go...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>You could stage a version of Charles Dickens' ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>this was a fantastic episode. i saw a clip fro...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>and laugh out loud funny in many scenes.&lt;br /&gt;...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bb2f13c-c731-4e9a-8446-d7101308082d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8bb2f13c-c731-4e9a-8446-d7101308082d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8bb2f13c-c731-4e9a-8446-d7101308082d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}],"source":["train_data.head()"]},{"cell_type":"markdown","metadata":{"id":"bTrbf15aROgj"},"source":["## <Font color = 'pickle'>**Create Train/Test/Valid Split**\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:53.741135Z","iopub.status.busy":"2022-10-02T10:36:53.740895Z","iopub.status.idle":"2022-10-02T10:36:53.765434Z","shell.execute_reply":"2022-10-02T10:36:53.765032Z","shell.execute_reply.started":"2022-10-02T10:36:53.741117Z"},"id":"9RFTtWvX7Vwr","executionInfo":{"status":"ok","timestamp":1665367500939,"user_tz":300,"elapsed":8,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["X, y = train_data['Reviews'].values, train_data['Labels'].values"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:54.579916Z","iopub.status.busy":"2022-10-02T10:36:54.579740Z","iopub.status.idle":"2022-10-02T10:36:54.605722Z","shell.execute_reply":"2022-10-02T10:36:54.605282Z","shell.execute_reply.started":"2022-10-02T10:36:54.579903Z"},"id":"a8sZ605P7mON","executionInfo":{"status":"ok","timestamp":1665367500939,"user_tz":300,"elapsed":8,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.20, random_state=42)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:36:55.365747Z","iopub.status.busy":"2022-10-02T10:36:55.365469Z","iopub.status.idle":"2022-10-02T10:36:55.390447Z","shell.execute_reply":"2022-10-02T10:36:55.390048Z","shell.execute_reply.started":"2022-10-02T10:36:55.365732Z"},"id":"AMapwMp88dBO","executionInfo":{"status":"ok","timestamp":1665367500939,"user_tz":300,"elapsed":8,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["X_test , y_test = test_data['Reviews'].values, test_data['Labels'].values"]},{"cell_type":"markdown","metadata":{"id":"yNsbSCsHQkrS"},"source":["## <Font color = 'pickle'>**Data PreProcessing**"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:39:45.327967Z","iopub.status.busy":"2022-10-02T10:39:45.327760Z","iopub.status.idle":"2022-10-02T10:42:41.127740Z","shell.execute_reply":"2022-10-02T10:42:41.127192Z","shell.execute_reply.started":"2022-10-02T10:39:45.327953Z"},"id":"GlDJV1QlqZPO","executionInfo":{"status":"ok","timestamp":1665367500940,"user_tz":300,"elapsed":9,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# X_train_cleaned = cp.SpacyPreprocessor(model = 'en_core_web_sm', batch_size=1000).transform(X_train)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:42:41.128992Z","iopub.status.busy":"2022-10-02T10:42:41.128816Z","iopub.status.idle":"2022-10-02T10:46:58.696982Z","shell.execute_reply":"2022-10-02T10:46:58.696446Z","shell.execute_reply.started":"2022-10-02T10:42:41.128979Z"},"id":"O30W-TXUsVIc","executionInfo":{"status":"ok","timestamp":1665367500940,"user_tz":300,"elapsed":9,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# X_valid_cleaned = cp.SpacyPreprocessor(model = 'en_core_web_sm', batch_size=1000).transform(X_valid)\n","# X_test_cleaned = cp.SpacyPreprocessor(model = 'en_core_web_sm', batch_size=1000).transform(X_test)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:46:58.697995Z","iopub.status.busy":"2022-10-02T10:46:58.697823Z","iopub.status.idle":"2022-10-02T10:46:58.720091Z","shell.execute_reply":"2022-10-02T10:46:58.719642Z","shell.execute_reply.started":"2022-10-02T10:46:58.697982Z"},"id":"4PBmReT_skM_","executionInfo":{"status":"ok","timestamp":1665367500941,"user_tz":300,"elapsed":9,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["X_train_cleaned_file = data_folder / 'x_train_cleaned_bag_of_words.pkl'\n","X_valid_cleaned_file = data_folder / 'x_valid_cleaned_bag_of_words..pkl'\n","X_test_cleaned_file = data_folder / 'x_test_cleaned_bag_of_words..pkl'"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:46:58.721114Z","iopub.status.busy":"2022-10-02T10:46:58.720953Z","iopub.status.idle":"2022-10-02T10:46:58.900841Z","shell.execute_reply":"2022-10-02T10:46:58.900393Z","shell.execute_reply.started":"2022-10-02T10:46:58.721101Z"},"id":"nK83ovH1s2jB","executionInfo":{"status":"ok","timestamp":1665367500941,"user_tz":300,"elapsed":9,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# joblib.dump(X_train_cleaned, X_train_cleaned_file)\n","# joblib.dump(X_valid_cleaned, X_valid_cleaned_file)\n","# joblib.dump(X_test_cleaned, X_test_cleaned_file)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:46:58.901490Z","iopub.status.busy":"2022-10-02T10:46:58.901353Z","iopub.status.idle":"2022-10-02T10:46:59.008992Z","shell.execute_reply":"2022-10-02T10:46:59.008412Z","shell.execute_reply.started":"2022-10-02T10:46:58.901477Z"},"id":"WVjfU8JUvDz5","executionInfo":{"status":"ok","timestamp":1665367501677,"user_tz":300,"elapsed":745,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["X_train_cleaned = joblib.load(X_train_cleaned_file)\n","X_valid_cleaned = joblib.load(X_valid_cleaned_file)\n","X_test_cleaned = joblib.load(X_test_cleaned_file)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:46:59.009604Z","iopub.status.busy":"2022-10-02T10:46:59.009469Z","iopub.status.idle":"2022-10-02T10:47:03.292582Z","shell.execute_reply":"2022-10-02T10:47:03.292024Z","shell.execute_reply.started":"2022-10-02T10:46:59.009591Z"},"id":"xx0-0QP48kCH","executionInfo":{"status":"ok","timestamp":1665367501677,"user_tz":300,"elapsed":3,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a564956d-ca93-451e-aaa2-9dd92f6db2c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n","<class 'numpy.ndarray'>\n"]}],"source":["print(type(X_train_cleaned))\n","print(type(y_train))"]},{"cell_type":"markdown","metadata":{"id":"FTIKaTsTgvYu"},"source":["## <Font color = 'pickle'>**Custom Dataset Class**"]},{"cell_type":"code","source":["class CustomDataset(torch.utils.data.Dataset):\n","    \"\"\"IMDB dataset.\"\"\"\n","\n","    def __init__(self, X, y):\n","        self.X = np.array(X)\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        text = self.X[idx]\n","        labels = self.y[idx]\n","        sample = (text, labels)\n","        \n","        return sample"],"metadata":{"id":"kul5dyeM2d4k","executionInfo":{"status":"ok","timestamp":1665367501677,"user_tz":300,"elapsed":2,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:48:16.574587Z","iopub.status.busy":"2022-10-02T10:48:16.573804Z","iopub.status.idle":"2022-10-02T10:48:16.598997Z","shell.execute_reply":"2022-10-02T10:48:16.598555Z","shell.execute_reply.started":"2022-10-02T10:48:16.574571Z"},"id":"R1mKoKSlAxAq","executionInfo":{"status":"ok","timestamp":1665367502938,"user_tz":300,"elapsed":1263,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["trainset = CustomDataset(X_train_cleaned,y_train)\n","validset = CustomDataset(X_valid_cleaned,y_valid)\n","testset = CustomDataset(X_test_cleaned,y_test)"]},{"cell_type":"markdown","metadata":{"id":"XoEVe7eGtY7U"},"source":["## <Font color = 'pickle'>**Create Vocab**"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"LRLHO-M1to6q","executionInfo":{"status":"ok","timestamp":1665367502938,"user_tz":300,"elapsed":2,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["def create_vocab(dataset, min_freq):\n","  counter = Counter()\n","  for (text, _) in dataset:\n","    counter.update(str(text).split())\n","  my_vocab = vocab(counter, min_freq=min_freq)\n","  my_vocab.insert_token('<unk>', 0)\n","  my_vocab.set_default_index(0)\n","  return my_vocab"]},{"cell_type":"markdown","source":["vocab should always be created based on trainset"],"metadata":{"id":"TY5oKhQlJPQL"}},{"cell_type":"code","execution_count":29,"metadata":{"id":"wNUi_aNctkAo","executionInfo":{"status":"ok","timestamp":1665367504069,"user_tz":300,"elapsed":1133,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["imdb_vocab = create_vocab(trainset, min_freq = 2)"]},{"cell_type":"code","source":["len(imdb_vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ask8H1QJJMZK","executionInfo":{"status":"ok","timestamp":1665367504069,"user_tz":300,"elapsed":5,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"f6dad462-6bde-4210-8aa2-30c99f24f6c9"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["36241"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665367504070,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"eyaeFqCsuRTQ","jupyter":{"outputs_hidden":true},"outputId":"016d7daf-e828-46c5-e8e6-2bf7e31e7428","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<unk>', 'production', 'absolutely', 'storyline', 'acting']"]},"metadata":{},"execution_count":31}],"source":["imdb_vocab.get_itos()[0:5]"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"WDMu8-JOujxY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665367504070,"user_tz":300,"elapsed":3,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"d98a6891-8ae3-4d0b-82ff-6ac201ab6a71"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":32}],"source":["imdb_vocab['abracadabra']"]},{"cell_type":"markdown","metadata":{"id":"ojvSMWR5u-LU"},"source":["## <Font color = 'pickle'>**Collate_fn for Data Loaders**"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"cdBKJlVmvB-9","executionInfo":{"status":"ok","timestamp":1665367504604,"user_tz":300,"elapsed":536,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# Creating a lambda function objects that will be used to get the indices of words from vocab\n","text_pipeline = lambda x: [imdb_vocab[token] for token in str(x).split()]\n","label_pipeline = lambda x: int(x)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"cL1TZVthvIT2","executionInfo":{"status":"ok","timestamp":1665367504604,"user_tz":300,"elapsed":2,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["'''\n","We know that input to the embedding layers are indices of words from the vocab.\n","The collate_batch() accepts batch of data and gets the indices of text from vocab and returns the same\n","We will include this collate_batch() in collat_fn attribute of DataLoader.\n","So it will create a batch of data containing indices of words and corresponding labels.\n","But for EmbeddingBag we need one more extra parameter, that is offset.\n","offsets determines the starting index position of each bag (sequence) in input.\n","'''\n","def collate_batch(batch):\n","    label_list, text_list, offsets = [], [], [0]\n","    for (_text, _label) in batch:\n","         label_list.append(label_pipeline(_label))\n","         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n","         text_list.append(processed_text)\n","         offsets.append(processed_text.size(0))\n","    label_list = torch.tensor(label_list, dtype=torch.int64)\n","    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n","    text_list = torch.cat(text_list)\n","    return text_list, label_list, offsets"]},{"cell_type":"markdown","metadata":{"id":"U5PslDp5R7Ff"},"source":["## <Font color = 'pickle'>**Check Data Loaders**\n","\n","Let us check if our collate function is working by creating a dataloader"]},{"cell_type":"code","source":["batch_size=2\n","check_loader= torch.utils.data.DataLoader(dataset=trainset,\n","                                        batch_size=batch_size,\n","                                        shuffle=True,\n","                                        collate_fn=collate_batch,\n","                                        num_workers=4)"],"metadata":{"id":"4ltYqq5e4NLD","executionInfo":{"status":"ok","timestamp":1665367504604,"user_tz":300,"elapsed":2,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["for text, label, offsets in check_loader:\n","  print(label, text, offsets)\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"logKAfqD4SXB","executionInfo":{"status":"ok","timestamp":1665367505757,"user_tz":300,"elapsed":1155,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"c10c8a49-1bf8-4366-8f98-4321dfffb8cf"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 1]) tensor([  122,   472,  1181,   272,    69,   126,   619,  2349,   472,   242,\n","         1420,  1862,   135,    97,     4,   395,  2738,  1493,  7696,   782,\n","          941,   746,   941,   172,  1401,    47,   154,    93,  1873,   984,\n","        10675,   122,   635, 16091,   537,   802,  3466,   376,  2591,  8728,\n","          130,  8789,  1161,  1800,    69,   122,   314,  4266,   542, 22252,\n","          220,   874,  4048, 16787,  1252,  1069,   741,  1832,   526,  6979,\n","         1776,  6115,   582,   961, 18422,  2600,  2396, 31744,   321,  1695,\n","        27206,  2837,   331, 22258,  3142,  1445, 18976,   441,   102, 11971,\n","        30472, 19007, 18422,   483,  8258,  9684,  4261,   542,  2336,   258,\n","         2034,  4305,   749, 14840, 15360, 16787,    82,  1872,  5991,  1472,\n","           67,     5, 18504,  3088, 11062,  2766,  4155,  6950,  1808,   209,\n","          362,   352,  1147,  1322,  1252,  1069,   172,  5076,  2135,   567,\n","         7262,  1665,   172,   349,  7039,    69]) tensor([ 0, 44])\n"]}]},{"cell_type":"markdown","metadata":{"id":"iQ60WJKlg3bQ"},"source":["# <font color = 'pickle'> **Functions to implement NN Training**"]},{"cell_type":"markdown","metadata":{"id":"3D7A5cBeFoAI"},"source":["Now, we will start implementing our Softmax Regression Model from scratch.\n","\n","We will now create following functions:\n","\n","- **Model**\n","- **Loss Function** \n","- **One Hot Encoding**\n","- **Training Loop for 1 epoch**\n","- **Validation Loop for 1 epoch**\n","- **Model Training** - repeat the training and validation loops for given number of epochs\n","- **Function to get the accuracy given the model**"]},{"cell_type":"markdown","metadata":{"id":"GLIXu5RaylkZ"},"source":["## <Font color = 'pickle'>**Model**"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T10:59:03.435895Z","iopub.status.busy":"2022-10-02T10:59:03.435684Z","iopub.status.idle":"2022-10-02T10:59:03.460780Z","shell.execute_reply":"2022-10-02T10:59:03.460317Z","shell.execute_reply.started":"2022-10-02T10:59:03.435881Z"},"id":"LNJY8GBipO2q","tags":[],"executionInfo":{"status":"ok","timestamp":1665367505757,"user_tz":300,"elapsed":6,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["class MLPCustom(nn.Module):\n","  def __init__(self, embed_dim, vocab_size, hidden_dim1, hidden_dim2, output_dim, non_linearity):\n","\n","    super().__init__()    \n","    self.hidden_dim1 = hidden_dim1\n","    self.hidden_dim2 = hidden_dim2\n","    self.output_dim = output_dim\n","    self.vocab_size = vocab_size\n","    self.embed_dim = embed_dim\n","\n","    self.non_linearity = non_linearity\n","\n","    \n","\n","    # embedding_layer\n","    self.embedding = nn.EmbeddingBag(self.vocab_size, self.embed_dim)\n","\n","    # hidden layer1\n","    self.hidden_layer1 = nn.Linear(self.embed_dim, self.hidden_dim1)\n","\n","    # dropout layer 1\n","    self.drop1 = nn.Dropout(p= 0.5)\n","\n","    # batch layer norm 1\n","    self.batchnorm1 = nn.BatchNorm1d(num_features=self.hidden_dim1)\n","\n","    # hideen layer2\n","    self.hidden_layer2 = nn.Linear(self.hidden_dim1, self.hidden_dim2)\n","    \n","    # dropout layer 2\n","    self.drop2 = nn.Dropout(p= 0.5)\n","\n","    # batch layer norm 2    \n","    self.batchnorm2 = nn.BatchNorm1d(num_features=self.hidden_dim2)\n","    \n","    # output layer\n","    self.output_layer = nn.Linear(self.hidden_dim2, self.output_dim)\n","\n","    # nonlinearity\n","\n","\n","  def forward(self, input_, offsets):\n","    embed_out = self.embedding(input_, offsets) # batchsize, embedding_dim\n","\n","    hout1 = self.non_linearity(self.hidden_layer1(embed_out)) # batchsize, hidden_dim1\n","    hout1 = self.batchnorm1(hout1)\n","    hout1 = self.drop1(hout1)\n","    \n","    hout2 = self.non_linearity(self.hidden_layer2(hout1)) # batchsize, hidden_dim2\n","    hout2 = self.batchnorm2(hout2)\n","    hout2 = self.drop2(hout2)\n","    \n","    ypred = self.output_layer(hout2) # batchsize, hidden_dim2\n","    \n","    # Note : We do not need to apply softmax as we will be using nn.CrossEntropy Loss\n","\n","    return ypred"]},{"cell_type":"markdown","metadata":{"id":"aqI_o6qwy6lb"},"source":["## <Font color = 'pickle'>**Function for Training  Loops**\n","\n","**Model Training** involves five steps: \n","\n","- Step 0: Randomly initialize parameters / weights\n","- Step 1: Compute model's predictions - forward pass\n","- Step 2: Compute loss\n","- Step 3: Compute the gradients\n","- Step 4: Update the parameters\n","- Step 5: Repeat steps 1 - 4\n","\n","Model training is repeating this process over and over, for many **epochs**.\n","\n","We will specify number of ***epochs*** and during each epoch we will iterate over the complete dataset and will keep on updating the parameters.\n","\n","***Learning rate*** and ***epochs*** are known as hyperparameters. We have to adjust the values of these two based on validation dataset.\n","\n","We will now create functions for step 1 to 4."]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T05:14:37.034571Z","iopub.status.busy":"2022-09-14T05:14:37.034212Z","iopub.status.idle":"2022-09-14T05:14:37.040441Z","shell.execute_reply":"2022-09-14T05:14:37.039923Z","shell.execute_reply.started":"2022-09-14T05:14:37.034554Z"},"id":"Pv4x22lZMn5p","tags":[],"executionInfo":{"status":"ok","timestamp":1665367505758,"user_tz":300,"elapsed":7,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["def train(train_loader, loss_function, model, optimizer, grad_clipping, max_norm, log_batch, log_interval):\n","\n","  # Training Loop \n","\n","  # initilalize variables as global\n","  # these counts will be updated every epoch\n","  global batch_ct_train\n","\n","  # Initialize train_loss at the he start of the epoch\n","  running_train_loss = 0\n","  running_train_correct = 0\n","  \n","  # put the model in training mode\n","\n","  model.train()\n","  # Iterate on batches from the dataset using train_loader\n","  for input_, targets, offsets in train_loader:\n","    \n","    # move inputs and outputs to GPUs\n","    input_ = input_.to(device)\n","    targets = targets.to(device)\n","    offsets = offsets.to(device)\n","\n","\n","    # Step 1: Forward Pass: Compute model's predictions \n","    output = model(input_, offsets)\n","    \n","    # Step 2: Compute loss\n","    loss = loss_function(output, targets)\n","\n","    # Correct prediction\n","    y_pred = torch.argmax(output, dim = 1)\n","    correct = torch.sum(y_pred == targets)\n","\n","    batch_ct_train += 1\n","\n","    # Step 3: Backward pass -Compute the gradients\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    # Gradient Clipping\n","    if grad_clipping:\n","      nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm, norm_type=2)\n","\n","    # Step 4: Update the parameters\n","    optimizer.step()\n","          \n","    # Add train loss of a batch \n","    running_train_loss += loss.item()\n","\n","    # Add Corect counts of a batch\n","    running_train_correct += correct\n","\n","    # log batch loss and accuracy\n","    if log_batch:\n","      if ((batch_ct_train + 1) % log_interval) == 0:\n","        wandb.log({f\"Train Batch Loss  :\": loss})\n","        wandb.log({f\"Train Batch Acc :\": correct/len(targets)})\n","\n","  \n","  # Calculate mean train loss for the whole dataset for a particular epoch\n","  train_loss = running_train_loss/len(train_loader)\n","\n","  # Calculate accuracy for the whole dataset for a particular epoch\n","  train_acc = running_train_correct/len(train_loader.dataset)\n","  \n","\n","  return train_loss, train_acc"]},{"cell_type":"markdown","metadata":{"id":"KeLm-GI5bW2V"},"source":["## <Font color = 'pickle'>**Function for Validation Loops**\n"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T05:14:37.041486Z","iopub.status.busy":"2022-09-14T05:14:37.041103Z","iopub.status.idle":"2022-09-14T05:14:37.045892Z","shell.execute_reply":"2022-09-14T05:14:37.045411Z","shell.execute_reply.started":"2022-09-14T05:14:37.041468Z"},"id":"pHP1WKDessiI","tags":[],"executionInfo":{"status":"ok","timestamp":1665367505758,"user_tz":300,"elapsed":7,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["def validate(valid_loader, loss_function, model, log_batch, log_interval):\n","\n","  # initilalize variables as global\n","  # these counts will be updated every epoch\n","  global batch_ct_valid\n","\n","  # Validation/Test loop\n","  # Initialize valid_loss at the he strat of the epoch\n","  running_val_loss = 0\n","  running_val_correct = 0\n","\n","  # put the model in evaluation mode\n","  model.eval()\n","\n","  with torch.no_grad():\n","    for input_, targets, offsets in valid_loader:\n","\n","      # move inputs and outputs to GPUs\n","      input_ = input_.to(device)\n","      targets = targets.to(device)\n","      offsets = offsets.to(device)\n","\n","      # Step 1: Forward Pass: Compute model's predictions \n","      output = model(input_, offsets)\n","\n","      # Step 2: Compute loss\n","      loss = loss_function(output, targets)\n","\n","      # Correct Predictions\n","      y_pred = torch.argmax(output, dim = 1)\n","      correct = torch.sum(y_pred == targets)\n","\n","      batch_ct_valid += 1\n","\n","      # Add val loss of a batch \n","      running_val_loss += loss.item()\n","\n","      # Add correct count for each batch\n","      running_val_correct += correct\n","\n","      # log batch loss and accuracy\n","      if log_batch:\n","        if ((batch_ct_valid + 1) % log_interval) == 0:\n","          wandb.log({f\"Valid Batch Loss  :\": loss})\n","          wandb.log({f\"Valid Batch Accuracy :\": correct/len(targets)})\n","\n","    # Calculate mean val loss for the whole dataset for a particular epoch\n","    val_loss = running_val_loss/len(valid_loader)\n","\n","    # Calculate accuracy for the whole dataset for a particular epoch\n","    val_acc = running_val_correct/len(valid_loader.dataset)\n","\n","    # scheduler step\n","    # scheduler.step(valid_loss)\n","    # scheduler.step()\n","    \n","  return val_loss, val_acc"]},{"cell_type":"markdown","metadata":{"id":"UwF70eqE6n_v"},"source":["## <Font color = 'pickle'>**Function for Model Training**\n","    \n","We will now create a function for step 5 of model training\n"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T05:14:37.046765Z","iopub.status.busy":"2022-09-14T05:14:37.046539Z","iopub.status.idle":"2022-09-14T05:14:37.052365Z","shell.execute_reply":"2022-09-14T05:14:37.051881Z","shell.execute_reply.started":"2022-09-14T05:14:37.046748Z"},"id":"KeCKVgg-5FiZ","tags":[],"executionInfo":{"status":"ok","timestamp":1665367505758,"user_tz":300,"elapsed":6,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["def train_loop(train_loader, valid_loader, model, optimizer, loss_function, epochs, device, patience, early_stopping,\n","               file_model):\n","    \n","  \"\"\" \n","  Function for training the model and plotting the graph for train & validation loss vs epoch.\n","  Input: iterator for train dataset, initial weights and bias, epochs, learning rate, batch size.\n","  Output: final weights, bias and train loss and validation loss for each epoch.\n","  \"\"\"\n","\n","  # Create lists to store train and val loss at each epoch\n","  train_loss_history = []\n","  valid_loss_history = []\n","  train_acc_history = []\n","  valid_acc_history = []\n","\n","  # initialize variables for early stopping\n","\n","  delta = 0\n","  best_score = None\n","  valid_loss_min = np.Inf\n","  counter_early_stop=0\n","  early_stop=False\n","\n","  # Iterate for the given number of epochs\n","  # Step 5: Repeat steps 1 - 4\n","\n","  for epoch in range(epochs):\n","\n","    t0 = datetime.now()\n","\n","    # Get train loss and accuracy for one epoch\n","    train_loss, train_acc = train(train_loader, loss_function, model, optimizer, \n","                                  wandb.config.GRAD_CLIPPING, wandb.config.MAX_NORM,\n","                                  wandb.config.LOG_BATCH, wandb.config.LOG_INTERVAL)\n","    valid_loss, valid_acc   = validate(valid_loader, loss_function, model, \n","                                       wandb.config.LOG_BATCH, wandb.config.LOG_INTERVAL)\n","\n","    dt = datetime.now() - t0\n","\n","    # Save history of the Losses and accuracy\n","    train_loss_history.append(train_loss)\n","    train_acc_history.append(train_acc)\n","\n","    valid_loss_history.append(valid_loss)\n","    valid_acc_history.append(valid_acc)\n","\n","    # Log the train and valid loss to wandb\n","    wandb.log({f\"Train Loss :\": train_loss, \"epoch\": epoch})\n","    wandb.log({f\"Train Acc :\": train_acc, \"epoch\": epoch})\n","\n","    wandb.log({f\"Valid Loss :\": valid_loss, \"epoch\": epoch})\n","    wandb.log({f\"Valid Acc :\": valid_acc, \"epoch\": epoch})\n","\n","    if early_stopping:\n","      score = -valid_loss\n","      if best_score is None:\n","        best_score=score\n","        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n","        torch.save(model.state_dict(), file_model)\n","        valid_loss_min = valid_loss\n","\n","      elif score < best_score + delta:\n","        counter_early_stop += 1\n","        print(f'Early stoping counter: {counter_early_stop} out of {patience}')\n","        if counter_early_stop > patience:\n","          early_stop = True\n","\n","\n","      else:\n","        best_score = score\n","        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n","        torch.save(model.state_dict(), file_model)\n","        counter_early_stop=0\n","        valid_loss_min = valid_loss\n","\n","      if early_stop:\n","        print('Early Stopping')\n","        break\n","\n","    else:\n","\n","      score = -valid_loss\n","      if best_score is None:\n","        best_score=score\n","        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n","        torch.save(model.state_dict(), file_model)\n","        valid_loss_min = valid_loss\n","\n","      elif score < best_score + delta:\n","        print(f'Validation loss has not decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Not Saving Model...')\n","      \n","      else:\n","        best_score = score\n","        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n","        torch.save(model.state_dict(), file_model)\n","        valid_loss_min = valid_loss\n","    \n","    # Print the train loss and accuracy for given number of epochs, batch size and number of samples\n","    print(f'Epoch : {epoch+1} / {epochs}')\n","    print(f'Time to complete {epoch+1} is {dt}')\n","    # print(f'Learning rate: {scheduler._last_lr[0]}')\n","    print(f'Train Loss: {train_loss : .4f} | Train Accuracy: {train_acc * 100 : .4f}%')\n","    print(f'Valid Loss: {valid_loss : .4f} | Valid Accuracy: {valid_acc * 100 : .4f}%')\n","    print()\n","    torch.cuda.empty_cache()\n","\n","  return train_loss_history, train_acc_history, valid_loss_history, valid_acc_history"]},{"cell_type":"markdown","metadata":{"id":"FWCLH47azD6j"},"source":["## <Font color = 'pickle'>**Function for Accuracy and Predictions**\n","\n","Now we have final values for weights and bias after training the model. We will use these values to make predictions on the test dataset."]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T05:14:37.053263Z","iopub.status.busy":"2022-09-14T05:14:37.052958Z","iopub.status.idle":"2022-09-14T05:14:37.057864Z","shell.execute_reply":"2022-09-14T05:14:37.057274Z","shell.execute_reply.started":"2022-09-14T05:14:37.053246Z"},"id":"M6KZqsnqQFVu","tags":[],"executionInfo":{"status":"ok","timestamp":1665367505759,"user_tz":300,"elapsed":7,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["def get_acc_pred(data_loader, model, device):\n","    \n","  \"\"\" \n","  Function to get predictions and accuracy for a given data using estimated model\n","  Input: Data iterator, Final estimated weoights, bias\n","  Output: Prections and Accuracy for given dataset\n","  \"\"\"\n","\n","  # Array to store predicted labels\n","  predictions = torch.Tensor() # empty tensor\n","  predictions = predictions.to(device) # move predictions to GPU\n","\n","  # Array to store actual labels\n","  y = torch.Tensor() # empty tensor\n","  y = y.to(device)\n","\n","  # put the model in evaluation mode\n","  model.eval()\n","  \n","  # Iterate over batches from data iterator\n","  with torch.no_grad():\n","    for input_, targets, offsets in data_loader:\n","      \n","      # move inputs and outputs to GPUs\n","      \n","      input_ = input_.to(device)\n","      targets = targets.to(device)\n","      offsets = offsets.to(device)\n","      \n","      # Calculated the predicted labels\n","      output = model(input_, offsets)\n","\n","      # Choose the label with maximum probability\n","      prediction = torch.argmax(output, dim = 1)\n","\n","      # Add the predicted labels to the array\n","      predictions = torch.cat((predictions, prediction)) \n","\n","      # Add the actual labels to the array\n","      y = torch.cat((y, targets)) \n","\n","  # Check for complete dataset if actual and predicted labels are same or not\n","  # Calculate accuracy\n","  acc = (predictions == y).float().mean()\n","\n","  # Return tuple containing predictions and accuracy\n","  return predictions, acc  "]},{"cell_type":"markdown","source":["# <Font color = 'pickle'>**Meta Data**"],"metadata":{"id":"5nF5iTy_VqdV"}},{"cell_type":"code","source":["hyperparameters = SimpleNamespace(\n","    EMBED_DIM = 300,\n","    VOCAB_SIZE = len(imdb_vocab),\n","    OUTPUT_DIM = 2,\n","    HIDDEN_DIM1 = 200,\n","    HIDDEN_DIM2 = 100,\n","    NON_LINEARITY= F.relu,\n","    EPOCHS = 50,\n","    \n","    BATCH_SIZE = 128,\n","    LEARNING_RATE = 0.001,\n","    DATASET=\"IMDB\",\n","    ARCHITECTUREe=\"Embed_2_hidden_layers\",\n","    LOG_INTERVAL = 25,\n","    LOG_BATCH = True,\n","    FILE_MODEL = model_folder/'imdb_2_hidden_layers.pt',\n","    GRAD_CLIPPING = False,\n","    MAX_NORM = 0,\n","    MOMENTUM = 0,\n","    PATIENCE = 5,\n","    EARLY_STOPPING = True,\n","    # SCHEDULER_FACTOR = 0,\n","    # SCHEDULER_PATIENCE = 0,\n","    WEIGHT_DECAY = 0.001\n","    )"],"metadata":{"id":"TAuG3mxBWHaz","executionInfo":{"status":"ok","timestamp":1665367505759,"user_tz":300,"elapsed":7,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oVk_RctgdPRP"},"source":["# <Font color = 'pickle'>**Data Loaders, Loss Function, Optimizer**"]},{"cell_type":"code","source":["# Initialize a new project\n","import random\n","wandb.init(name = 'Embed_2_hidden_layers', project = 'NLP_MLP_imdb')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":91},"id":"3kCRNDlu-zbE","executionInfo":{"status":"ok","timestamp":1665367508375,"user_tz":300,"elapsed":2623,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"45a19b15-298e-4772-9bf3-e99fe83bda08"},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.4"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20221010_020504-28dt07d1</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/hsingh-utd/NLP_MLP_imdb/runs/28dt07d1\" target=\"_blank\">Embed_2_hidden_layers</a></strong> to <a href=\"https://wandb.ai/hsingh-utd/NLP_MLP_imdb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/hsingh-utd/NLP_MLP_imdb/runs/28dt07d1?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7fa8a78eca50>"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["wandb.config = hyperparameters\n","wandb.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gnl8vsAN-5Tq","executionInfo":{"status":"ok","timestamp":1665367508375,"user_tz":300,"elapsed":4,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"7e5b1a00-cf78-43ba-8928-05f9dc84051f"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["namespace(ARCHITECTUREe='Embed_2_hidden_layers', BATCH_SIZE=128, DATASET='IMDB', EARLY_STOPPING=True, EMBED_DIM=300, EPOCHS=50, FILE_MODEL=PosixPath('/content/drive/MyDrive/data/models/nlp_fall_2022/imdb/imdb_2_hidden_layers.pt'), GRAD_CLIPPING=False, HIDDEN_DIM1=200, HIDDEN_DIM2=100, LEARNING_RATE=0.001, LOG_BATCH=True, LOG_INTERVAL=25, MAX_NORM=0, MOMENTUM=0, NON_LINEARITY=<function relu at 0x7fa9b6bc9200>, OUTPUT_DIM=2, PATIENCE=5, VOCAB_SIZE=36241, WEIGHT_DECAY=0.001)"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:18:45.004101Z","iopub.status.busy":"2022-10-02T11:18:45.003880Z","iopub.status.idle":"2022-10-02T11:18:55.147743Z","shell.execute_reply":"2022-10-02T11:18:55.147122Z","shell.execute_reply.started":"2022-10-02T11:18:45.004087Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665367508375,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"fZ6ZoM9WaS_M","tags":[]},"outputs":[],"source":["# Fix seed value\n","SEED = 2345\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","# Data Loader\n","train_loader = torch.utils.data.DataLoader(trainset, batch_size=wandb.config.BATCH_SIZE, shuffle = True, \n","                                           collate_fn=collate_batch, num_workers = 4)\n","valid_loader = torch.utils.data.DataLoader(validset, batch_size=wandb.config.BATCH_SIZE, shuffle = False, \n","                                           collate_fn=collate_batch,  num_workers = 4)\n","test_loader = torch.utils.data.DataLoader(testset, batch_size=wandb.config.BATCH_SIZE,   shuffle = False, \n","                                          collate_fn=collate_batch,  num_workers = 4)\n","\n","# cross entropy loss function\n","loss_function = nn.CrossEntropyLoss()\n","\n","# use GPUs\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","wandb.config.DEVICE = device\n","\n","# model \n","model_imdb = MLPCustom(wandb.config.EMBED_DIM, \n","                       wandb.config.VOCAB_SIZE, \n","                       wandb.config.HIDDEN_DIM1, \n","                       wandb.config.HIDDEN_DIM2,\n","                       wandb.config.OUTPUT_DIM, \n","                       wandb.config.NON_LINEARITY)\n","\n","model_imdb.to(wandb.config.DEVICE)\n","\n","def init_weights(m):\n","  if type(m) == nn.Linear:\n","      torch.nn.init.kaiming_normal_(m.weight)\n","      torch.nn.init.zeros_(m.bias)\n","        \n","# apply initialization recursively  to all modules\n","model_imdb.apply(init_weights)\n","\n","# Intialize stochiastic gradient descent optimizer\n","optimizer = torch.optim.Adam(model_imdb.parameters(), \n","                             lr = wandb.config.LEARNING_RATE, \n","                             weight_decay=wandb.config.WEIGHT_DECAY)\n","\n","wandb.config.OPTIMIZER = optimizer\n","\n","# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor= wandb.config.scheduler_factor, \n","#                              patience=wandb.config.scheduler_patience, verbose=True)\n","\n","#scheduler = StepLR(optimizer, gamma=0.4,step_size=1, verbose=True)"]},{"cell_type":"code","source":["wandb.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6etbfbQkm-zv","executionInfo":{"status":"ok","timestamp":1665367509094,"user_tz":300,"elapsed":722,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"096dbac8-e5cd-49da-e285-5db91648f14e"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["namespace(ARCHITECTUREe='Embed_2_hidden_layers', BATCH_SIZE=128, DATASET='IMDB', DEVICE=device(type='cuda', index=0), EARLY_STOPPING=True, EMBED_DIM=300, EPOCHS=50, FILE_MODEL=PosixPath('/content/drive/MyDrive/data/models/nlp_fall_2022/imdb/imdb_2_hidden_layers.pt'), GRAD_CLIPPING=False, HIDDEN_DIM1=200, HIDDEN_DIM2=100, LEARNING_RATE=0.001, LOG_BATCH=True, LOG_INTERVAL=25, MAX_NORM=0, MOMENTUM=0, NON_LINEARITY=<function relu at 0x7fa9b6bc9200>, OPTIMIZER=Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    eps: 1e-08\n","    foreach: None\n","    lr: 0.001\n","    maximize: False\n","    weight_decay: 0.001\n","), OUTPUT_DIM=2, PATIENCE=5, VOCAB_SIZE=36241, WEIGHT_DECAY=0.001)"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["# <Font color = 'pickle'>**Sanity Check**\n","- Check the loss without any training. For Cross entropy the expected value will be log(number of classes)"],"metadata":{"id":"ffeGh2dcukdK"}},{"cell_type":"code","source":["for input_, targets, offsets in train_loader:\n","  \n","  # move inputs and outputs to GPUs\n","  input_ = input_.to(device)\n","  targets = targets.to(device)\n","  offsets = offsets.to(device)\n","  model_imdb.eval()\n","  # Forward pass\n","  output = model_imdb(input_, offsets)\n","  loss = loss_function(output, targets)\n","  print(f'Actual loss: {loss}')\n","  break\n","\n","print(f'Expected Theoretical loss: {np.log(2)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p2Gx7jgbumux","executionInfo":{"status":"ok","timestamp":1665367510064,"user_tz":300,"elapsed":972,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"e95164e5-7e89-4b89-9cc4-dba5a4e16f71"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Actual loss: 0.7161325216293335\n","Expected Theoretical loss: 0.6931471805599453\n"]}]},{"cell_type":"markdown","metadata":{"id":"e0_zWk0Ib74K"},"source":["# <Font color = 'pickle'>**Training Model**"]},{"cell_type":"code","source":["wandb.watch(model_imdb, log = 'all', log_freq=25, log_graph=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KczRQvKwiH_y","executionInfo":{"status":"ok","timestamp":1665367510064,"user_tz":300,"elapsed":4,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"5d95b6b2-6517-4b4c-b4ac-86399fe3f18d"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"]},{"output_type":"execute_result","data":{"text/plain":["[<wandb.wandb_torch.TorchGraph at 0x7fa8a76a7590>]"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T11:18:59.063373Z","iopub.status.busy":"2022-10-02T11:18:59.063161Z","iopub.status.idle":"2022-10-02T11:19:10.388677Z","shell.execute_reply":"2022-10-02T11:19:10.388079Z","shell.execute_reply.started":"2022-10-02T11:18:59.063359Z"},"executionInfo":{"elapsed":84599,"status":"ok","timestamp":1665367594662,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"LckLb_9bhZDw","outputId":"6c96795a-d04a-40ca-8cbc-a0d0517f4a7d","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation loss has decreased (inf --> 0.546675). Saving Model...\n","Epoch : 1 / 50\n","Time to complete 1 is 0:00:03.683584\n","Train Loss:  0.8629 | Train Accuracy:  60.1350%\n","Valid Loss:  0.5467 | Valid Accuracy:  72.6200%\n","\n","Validation loss has decreased (0.546675 --> 0.508445). Saving model...\n","Epoch : 2 / 50\n","Time to complete 2 is 0:00:03.835472\n","Train Loss:  0.6051 | Train Accuracy:  69.0250%\n","Valid Loss:  0.5084 | Valid Accuracy:  75.9800%\n","\n","Validation loss has decreased (0.508445 --> 0.485896). Saving model...\n","Epoch : 3 / 50\n","Time to complete 3 is 0:00:05.329176\n","Train Loss:  0.5267 | Train Accuracy:  73.8300%\n","Valid Loss:  0.4859 | Valid Accuracy:  77.8200%\n","\n","Validation loss has decreased (0.485896 --> 0.456259). Saving model...\n","Epoch : 4 / 50\n","Time to complete 4 is 0:00:04.208974\n","Train Loss:  0.4857 | Train Accuracy:  76.7550%\n","Valid Loss:  0.4563 | Valid Accuracy:  79.8200%\n","\n","Validation loss has decreased (0.456259 --> 0.434745). Saving model...\n","Epoch : 5 / 50\n","Time to complete 5 is 0:00:04.243996\n","Train Loss:  0.4575 | Train Accuracy:  78.6750%\n","Valid Loss:  0.4347 | Valid Accuracy:  81.0000%\n","\n","Validation loss has decreased (0.434745 --> 0.412722). Saving model...\n","Epoch : 6 / 50\n","Time to complete 6 is 0:00:03.852868\n","Train Loss:  0.4208 | Train Accuracy:  80.9800%\n","Valid Loss:  0.4127 | Valid Accuracy:  82.4600%\n","\n","Validation loss has decreased (0.412722 --> 0.396679). Saving model...\n","Epoch : 7 / 50\n","Time to complete 7 is 0:00:03.788733\n","Train Loss:  0.3924 | Train Accuracy:  82.5650%\n","Valid Loss:  0.3967 | Valid Accuracy:  82.8200%\n","\n","Validation loss has decreased (0.396679 --> 0.380533). Saving model...\n","Epoch : 8 / 50\n","Time to complete 8 is 0:00:03.795602\n","Train Loss:  0.3686 | Train Accuracy:  83.7550%\n","Valid Loss:  0.3805 | Valid Accuracy:  84.0000%\n","\n","Validation loss has decreased (0.380533 --> 0.369193). Saving model...\n","Epoch : 9 / 50\n","Time to complete 9 is 0:00:03.678114\n","Train Loss:  0.3432 | Train Accuracy:  85.2750%\n","Valid Loss:  0.3692 | Valid Accuracy:  84.7000%\n","\n","Validation loss has decreased (0.369193 --> 0.353895). Saving model...\n","Epoch : 10 / 50\n","Time to complete 10 is 0:00:03.837897\n","Train Loss:  0.3151 | Train Accuracy:  86.7550%\n","Valid Loss:  0.3539 | Valid Accuracy:  85.6200%\n","\n","Early stoping counter: 1 out of 5\n","Epoch : 11 / 50\n","Time to complete 11 is 0:00:03.905984\n","Train Loss:  0.2955 | Train Accuracy:  87.5400%\n","Valid Loss:  0.3540 | Valid Accuracy:  85.3600%\n","\n","Validation loss has decreased (0.353895 --> 0.345140). Saving model...\n","Epoch : 12 / 50\n","Time to complete 12 is 0:00:04.082596\n","Train Loss:  0.2781 | Train Accuracy:  88.5100%\n","Valid Loss:  0.3451 | Valid Accuracy:  86.1600%\n","\n","Validation loss has decreased (0.345140 --> 0.341746). Saving model...\n","Epoch : 13 / 50\n","Time to complete 13 is 0:00:03.819101\n","Train Loss:  0.2622 | Train Accuracy:  89.1500%\n","Valid Loss:  0.3417 | Valid Accuracy:  86.9600%\n","\n","Validation loss has decreased (0.341746 --> 0.339454). Saving model...\n","Epoch : 14 / 50\n","Time to complete 14 is 0:00:03.785391\n","Train Loss:  0.2421 | Train Accuracy:  90.1150%\n","Valid Loss:  0.3395 | Valid Accuracy:  86.9800%\n","\n","Validation loss has decreased (0.339454 --> 0.329462). Saving model...\n","Epoch : 15 / 50\n","Time to complete 15 is 0:00:03.803818\n","Train Loss:  0.2296 | Train Accuracy:  90.6300%\n","Valid Loss:  0.3295 | Valid Accuracy:  87.1400%\n","\n","Early stoping counter: 1 out of 5\n","Epoch : 16 / 50\n","Time to complete 16 is 0:00:03.830141\n","Train Loss:  0.2171 | Train Accuracy:  91.1500%\n","Valid Loss:  0.3438 | Valid Accuracy:  86.9800%\n","\n","Early stoping counter: 2 out of 5\n","Epoch : 17 / 50\n","Time to complete 17 is 0:00:03.646198\n","Train Loss:  0.2015 | Train Accuracy:  91.9950%\n","Valid Loss:  0.3371 | Valid Accuracy:  87.4600%\n","\n","Early stoping counter: 3 out of 5\n","Epoch : 18 / 50\n","Time to complete 18 is 0:00:03.870390\n","Train Loss:  0.1999 | Train Accuracy:  92.0500%\n","Valid Loss:  0.3465 | Valid Accuracy:  87.2600%\n","\n","Early stoping counter: 4 out of 5\n","Epoch : 19 / 50\n","Time to complete 19 is 0:00:03.872230\n","Train Loss:  0.1892 | Train Accuracy:  92.4850%\n","Valid Loss:  0.3339 | Valid Accuracy:  87.5200%\n","\n","Early stoping counter: 5 out of 5\n","Epoch : 20 / 50\n","Time to complete 20 is 0:00:03.865537\n","Train Loss:  0.1844 | Train Accuracy:  92.6500%\n","Valid Loss:  0.3933 | Valid Accuracy:  86.4800%\n","\n","Early stoping counter: 6 out of 5\n","Early Stopping\n"]}],"source":["# See live graphs in the notebook.\n","#%%wandb \n","batch_ct_train, batch_ct_valid = 0, 0\n","train_loss_history, train_acc_history, valid_loss_history, valid_acc_history = train_loop(train_loader, \n","                                                                                          valid_loader, \n","                                                                                          model_imdb, \n","                                                                                          optimizer,\n","                                                                                          loss_function, \n","                                                                                          wandb.config.EPOCHS, \n","                                                                                          wandb.config.DEVICE,\n","                                                                                          wandb.config.PATIENCE, \n","                                                                                          wandb.config.EARLY_STOPPING,\n","                                                                                          wandb.config.FILE_MODEL)"]},{"cell_type":"markdown","metadata":{"id":"c-Cj1f2Qb74K"},"source":["# <Font color = 'pickle'>**Get Accuracy, Predictions**"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T11:19:29.297644Z","iopub.status.busy":"2022-10-02T11:19:29.297419Z","iopub.status.idle":"2022-10-02T11:19:29.322096Z","shell.execute_reply":"2022-10-02T11:19:29.321716Z","shell.execute_reply.started":"2022-10-02T11:19:29.297629Z"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1665367594662,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"dZQF1CbgKEKd","outputId":"0a541158-77a6-4332-c65d-b0a7a539a78f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":50}],"source":["device"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:19:30.196257Z","iopub.status.busy":"2022-10-02T11:19:30.196043Z","iopub.status.idle":"2022-10-02T11:19:30.449031Z","shell.execute_reply":"2022-10-02T11:19:30.448679Z","shell.execute_reply.started":"2022-10-02T11:19:30.196243Z"},"id":"yw7GhoZuRdIO","tags":[],"executionInfo":{"status":"ok","timestamp":1665367594663,"user_tz":300,"elapsed":17,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"69a5cff6-8617-4595-9c6c-940cad067c77"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":51}],"source":["model_nn = MLPCustom(wandb.config.EMBED_DIM, wandb.config.VOCAB_SIZE, wandb.config.HIDDEN_DIM1, wandb.config.HIDDEN_DIM2, \n","                  wandb.config.OUTPUT_DIM, wandb.config.NON_LINEARITY)\n","model_nn.to(device)\n","model_nn.load_state_dict(torch.load(wandb.config.FILE_MODEL))"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:19:31.086069Z","iopub.status.busy":"2022-10-02T11:19:31.085837Z","iopub.status.idle":"2022-10-02T11:19:31.117082Z","shell.execute_reply":"2022-10-02T11:19:31.116628Z","shell.execute_reply.started":"2022-10-02T11:19:31.086054Z"},"executionInfo":{"elapsed":3928,"status":"ok","timestamp":1665367598576,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"3v2z0oFcRjrF","tags":[]},"outputs":[],"source":["# Get the prediction and accuracy for the test dataseta\n","predictions_test, acc_test = get_acc_pred(test_loader, model_nn, device)\n","predictions_train, acc_train = get_acc_pred(train_loader, model_nn, device)\n","predictions_valid, acc_valid = get_acc_pred(valid_loader, model_nn, device)"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:19:31.696329Z","iopub.status.busy":"2022-10-02T11:19:31.696121Z","iopub.status.idle":"2022-10-02T11:19:31.721995Z","shell.execute_reply":"2022-10-02T11:19:31.721442Z","shell.execute_reply.started":"2022-10-02T11:19:31.696314Z"},"id":"vcfIlMd3FKAX","tags":[],"executionInfo":{"status":"ok","timestamp":1665367598577,"user_tz":300,"elapsed":19,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c5f542d6-e374-466c-a205-0b8d8d74757d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy tensor(84.5040, device='cuda:0')\n","Train accuracy tensor(95.4350, device='cuda:0')\n","Valid accuracy tensor(87.1400, device='cuda:0')\n"]}],"source":["# Print Test Accuracy\n","print('Test accuracy', acc_test * 100)\n","print('Train accuracy', acc_train * 100)\n","print('Valid accuracy', acc_valid * 100)"]},{"cell_type":"code","source":["wandb.log({'Best_test_Acc': acc_test})\n","wandb.log({'Best_train_Acc': acc_train})\n","wandb.log({'Best_valid_Acc': acc_valid})"],"metadata":{"id":"ZXfjniBJjX3u","executionInfo":{"status":"ok","timestamp":1665367598577,"user_tz":300,"elapsed":17,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"caRp4G3ov5fp"},"source":["# <Font color = 'pickle'>**Confusion Matrix for Test Data**"]},{"cell_type":"markdown","metadata":{"id":"GZf0pSyQV32m"},"source":["Now, we will make some visualizations for the predictions that we obtained."]},{"cell_type":"markdown","metadata":{"id":"5sQH0GvxXnam"},"source":["We will construct a `confusion matrix` which will help us to visualize the performance of our classification model on the test dataset as we know the true values for the test data."]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:36:26.514609Z","iopub.status.busy":"2022-10-02T11:36:26.514407Z","iopub.status.idle":"2022-10-02T11:36:26.542565Z","shell.execute_reply":"2022-10-02T11:36:26.541979Z","shell.execute_reply.started":"2022-10-02T11:36:26.514594Z"},"id":"NaiRaPuQYYIV","tags":[],"executionInfo":{"status":"ok","timestamp":1665367598578,"user_tz":300,"elapsed":17,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# Get an array containing actual labels\n","testing_labels = testset.y"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-10-02T11:36:45.576258Z","iopub.status.busy":"2022-10-02T11:36:45.576049Z","iopub.status.idle":"2022-10-02T11:36:45.600946Z","shell.execute_reply":"2022-10-02T11:36:45.600399Z","shell.execute_reply.started":"2022-10-02T11:36:45.576245Z"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1665367598578,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"wMuZ1Yl2X47z","outputId":"8972c858-ac4e-4c70-cc38-dad5a333b2b8","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1])"]},"metadata":{},"execution_count":56}],"source":["np.unique(testing_labels)"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:37:32.039417Z","iopub.status.busy":"2022-10-02T11:37:32.039204Z","iopub.status.idle":"2022-10-02T11:37:32.325754Z","shell.execute_reply":"2022-10-02T11:37:32.325164Z","shell.execute_reply.started":"2022-10-02T11:37:32.039403Z"},"id":"lAtBZumJcuwX","tags":[],"executionInfo":{"status":"ok","timestamp":1665367599710,"user_tz":300,"elapsed":1147,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# Log a confusion matrix to W&B\n","wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(\n","                        probs = None,\n","                        y_true = testing_labels,\n","                        preds = predictions_test.to('cpu').numpy(),\n","                        class_names =['negative', 'positive'])})"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":495},"execution":{"iopub.execute_input":"2022-10-02T11:37:35.481530Z","iopub.status.busy":"2022-10-02T11:37:35.481317Z","iopub.status.idle":"2022-10-02T11:37:40.670611Z","shell.execute_reply":"2022-10-02T11:37:40.670287Z","shell.execute_reply.started":"2022-10-02T11:37:35.481517Z"},"executionInfo":{"elapsed":8169,"status":"ok","timestamp":1665367607857,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"jIlsxRdPHZYa","outputId":"0952b9e7-ae82-4d63-8837-63d6ae5bfbca","tags":[]},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Best_test_Acc</td><td>▁</td></tr><tr><td>Best_train_Acc</td><td>▁</td></tr><tr><td>Best_valid_Acc</td><td>▁</td></tr><tr><td>Train Acc :</td><td>▁▃▄▅▅▅▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>Train Batch Acc :</td><td>▁▁▃▃▂▄▅▅▄▃▅▅▅▄▅▅▆▆▅▆▅▆▆▆▆▇▆▇▇▇▆█▆▇▇█▇█▇▇</td></tr><tr><td>Train Batch Loss  :</td><td>█▇▆▆▆▅▄▄▅▅▄▄▄▃▄▄▃▄▄▂▃▂▃▃▃▂▃▂▂▂▃▂▃▂▂▁▂▂▂▃</td></tr><tr><td>Train Loss :</td><td>█▅▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Valid Acc :</td><td>▁▃▃▄▅▆▆▆▇▇▇▇█████████</td></tr><tr><td>Valid Batch Accuracy :</td><td>▂▁▂▂▃▁▂▂▃▅▃▄▅▃▃▄▅▅▄▆▅▆▃▆▆▅▅█▇▅▄▅▃</td></tr><tr><td>Valid Batch Loss  :</td><td>▇██▇▆▇▇▆▆▄▆▄▃▅▆▅▄▃▅▁▂▄▅▄▄▂▆▁▁▄▅▄▆</td></tr><tr><td>Valid Loss :</td><td>█▇▆▅▄▄▃▃▂▂▂▂▁▁▁▁▁▂▁▃▂</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best_test_Acc</td><td>0.84504</td></tr><tr><td>Best_train_Acc</td><td>0.95435</td></tr><tr><td>Best_valid_Acc</td><td>0.8714</td></tr><tr><td>Train Acc :</td><td>0.93115</td></tr><tr><td>Train Batch Acc :</td><td>0.89844</td></tr><tr><td>Train Batch Loss  :</td><td>0.23515</td></tr><tr><td>Train Loss :</td><td>0.17563</td></tr><tr><td>Valid Acc :</td><td>0.8722</td></tr><tr><td>Valid Batch Accuracy :</td><td>0.82812</td></tr><tr><td>Valid Batch Loss  :</td><td>0.40363</td></tr><tr><td>Valid Loss :</td><td>0.35386</td></tr><tr><td>epoch</td><td>20</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">Embed_2_hidden_layers</strong>: <a href=\"https://wandb.ai/hsingh-utd/NLP_MLP_imdb/runs/28dt07d1\" target=\"_blank\">https://wandb.ai/hsingh-utd/NLP_MLP_imdb/runs/28dt07d1</a><br/>Synced 5 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221010_020504-28dt07d1/logs</code>"]},"metadata":{}}],"source":["wandb.finish()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}