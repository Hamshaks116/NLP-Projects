{"cells":[{"cell_type":"markdown","metadata":{"id":"xtZUZxRsjFOZ"},"source":["# <font color = 'pickle'> Import/install Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-09-11T06:22:19.350046Z","iopub.status.busy":"2021-09-11T06:22:19.349510Z","iopub.status.idle":"2021-09-11T06:24:21.663679Z","shell.execute_reply":"2021-09-11T06:24:21.661932Z","shell.execute_reply.started":"2021-09-11T06:22:19.349987Z"},"id":"Rb6lO2qzxCEh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662989116329,"user_tz":300,"elapsed":23988,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"e512b430-d30d-4bb6-fa9b-f43913abf426"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-09-12 13:25:10.403564: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","\u001b[K     |████████████████████████████████| 12.8 MB 30.0 MB/s \n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n"]}],"source":["# install nltk\n","!pip install nltk -qq\n","# install spacy\n","!pip install -U spacy -qq\n","# download spacy model\n","!python -m spacy download en_core_web_sm -qq"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29260,"status":"ok","timestamp":1662989145586,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"T0nri2djPi_D","outputId":"04ba4145-1d07-4a55-f7c6-72991b2e37d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T20:24:56.540071Z","iopub.status.busy":"2021-09-11T20:24:56.539257Z","iopub.status.idle":"2021-09-11T20:24:56.544797Z","shell.execute_reply":"2021-09-11T20:24:56.544485Z","shell.execute_reply.started":"2021-09-11T20:24:56.539974Z"},"executionInfo":{"elapsed":5970,"status":"ok","timestamp":1662989151554,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"NBkcfK5xQkjv","outputId":"f34bac7a-fc82-4dcf-c699-9e28c499b095","tags":[]},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["from pathlib import Path\n","\n","import re\n","import sys\n","import textwrap as tw\n","import pandas as pd\n","import numpy as np\n","from  collections import OrderedDict as odict\n","\n","import spacy\n","\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","# Import TweetTokenizer from nltk.tokenize module\n","from nltk.tokenize import TweetTokenizer\n","# import vectorizers - main of this lecture\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1662989151554,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"t2_XksvXxCEj","outputId":"bfa443ea-f9ab-497c-854a-20f0d5eb6ca8","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'3.4.1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["spacy.__version__"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-09-11T20:24:57.977969Z","iopub.status.busy":"2021-09-11T20:24:57.977420Z","iopub.status.idle":"2021-09-11T20:24:57.984812Z","shell.execute_reply":"2021-09-11T20:24:57.983644Z","shell.execute_reply.started":"2021-09-11T20:24:57.977905Z"},"id":"sBtTl9hExCEk","tags":[],"executionInfo":{"status":"ok","timestamp":1662989151555,"user_tz":300,"elapsed":4,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["base_folder = Path('/content/drive/MyDrive/data')\n","data_folder = base_folder/'datasets'"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-09-11T20:24:59.919129Z","iopub.status.busy":"2021-09-11T20:24:59.918662Z","iopub.status.idle":"2021-09-11T20:25:00.179324Z","shell.execute_reply":"2021-09-11T20:25:00.178886Z","shell.execute_reply.started":"2021-09-11T20:24:59.919114Z"},"id":"PmZmCvuQQezx","tags":[],"executionInfo":{"status":"ok","timestamp":1662989152740,"user_tz":300,"elapsed":1189,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# load spacy model\n","nlp = spacy.load('en_core_web_sm')"]},{"cell_type":"markdown","metadata":{"id":"bzV0Las4fygR"},"source":["# <font color = 'pickle'> Bag of Words (Sparse Embeddings)\n"]},{"cell_type":"markdown","metadata":{"id":"aEeEQp3Pf8Kl"},"source":["## <font color = 'pickle'>**What is Bag of Words (BoW)?**\n","\n","A **bag-of-words** is a representation of text that describes the occurrence of words within a document disregarding grammar and word order. It involves two steps:\n","\n","    1. Create Vocabulary. Each word in vocabulary forms feature(independent variable) to represent document.\n","    2. Score words (based on frequency) to create Vectors."]},{"cell_type":"markdown","metadata":{"id":"pmUenp0Q4YDU"},"source":["## <font color = 'pickle'> **Why do you need to learn Bag of Words?**\n","\n","- Till now we have learnt how to pre-process the text data i.e clean the text data.\n","- Our final goal is to use text data in Machine Learning (ML) models. For example - we want to predict whether e-mail is a spam or not based on the text of the data. \n","- But ML models can understand only numbers. Therefore we need to convert text to vectors (numbers).\n","- The simple method of converting text to numbers is to use 'Bag of Words approach'\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kzKYz9DZ4YDU"},"source":["## <font color = 'pickle'>**Learning Outcome** </font>\n","After completing this tutorial, you will know\n","\n","1. What the bag-of-words approach is and how you can use it to represent text data.\n","2. What are different techniques to prepare a vocabulary and score words.\n","3. How to implement 'Bag-of-words' approach in python using sklearn."]},{"cell_type":"markdown","metadata":{"id":"uTmQrTrVxCEh"},"source":["# <font color = 'pickle'> **Tutorial Overview**\n"," - Generating Vocab\n"," - Generating vectors using Vocab\n","     - Binary Vectorizer\n","     - Count Vectorizer\n","     - tfidf Vectorizer\n"," \n"," - Modifying Vocab\n"," - Example - IMDB Dataset\n"]},{"cell_type":"markdown","metadata":{"id":"RTlvVAjziFYm"},"source":["## <font color = 'pickle'> **Generating Vocab**"]},{"cell_type":"markdown","metadata":{"id":"whv4QgKPB0Gv"},"source":["###  <font color = 'pickle'> **Dummy Corpus**"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-09-11T20:25:03.583435Z","iopub.status.busy":"2021-09-11T20:25:03.582835Z","iopub.status.idle":"2021-09-11T20:25:03.590454Z","shell.execute_reply":"2021-09-11T20:25:03.589100Z","shell.execute_reply.started":"2021-09-11T20:25:03.583366Z"},"id":"YzXnofA3nF3W","tags":[],"executionInfo":{"status":"ok","timestamp":1662989152741,"user_tz":300,"elapsed":3,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# Dummy corpus\n","Corpus = [\"Count Vectorizer - for this vectorizer, scoring is done based on frequency. For this vectorizer frequency is key. @vectorizer #frequency @frequency\",\n","          \"tfidf vectorizer - for this vectorizer, scoring is done based on tfidf,  higher tfidf higher score #tfidf @vectorizer \"  ,\n","          \"Binary vectorizer -for this vectorizer, scoring is done based on presence of word. For this vectorizer, dummy is key #dummy @dummy @vectorizer \"]\n","        "]},{"cell_type":"markdown","metadata":{"id":"lyhgUzi5CNgg"},"source":["### <font color = 'pickle'>**Create an instance of Vectorizer**"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-09-11T20:25:17.155888Z","iopub.status.busy":"2021-09-11T20:25:17.155757Z","iopub.status.idle":"2021-09-11T20:25:17.158014Z","shell.execute_reply":"2021-09-11T20:25:17.157740Z","shell.execute_reply.started":"2021-09-11T20:25:17.155874Z"},"id":"J3ZVqkIHCePq","tags":[],"executionInfo":{"status":"ok","timestamp":1662989152741,"user_tz":300,"elapsed":2,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["vectorizer = CountVectorizer()"]},{"cell_type":"code","source":["CountVectorizer??"],"metadata":{"id":"k5fgQ7Kb_9j3","executionInfo":{"status":"ok","timestamp":1662989152970,"user_tz":300,"elapsed":231,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u6kX6-YQCSuq"},"source":["### <font color = 'pickle'>**Fit Vectorizer on corpus to generate vocab**"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183,"status":"ok","timestamp":1662989153152,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"fnehlHO7RQKx","outputId":"9c1b0a11-d275-4356-88e0-5af4ad5fe9c1","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CountVectorizer()"]},"metadata":{},"execution_count":10}],"source":["# Fit the vectorizer on corpus\n","vectorizer.fit(Corpus)"]},{"cell_type":"markdown","metadata":{"id":"R-8UMn_FSNCF"},"source":["<font color = 'indianred'>**Vectorizer().fit() does the following**:\n","* lowercases your text \n","* uses utf-8 encoding\n","* performs tokenization (converts raw text to smaller units of text)\n","* uses word level tokenization (meaning each word is treated as a separate token) and  ignores single characters during tokenization ( words like ‘a’ and ‘I’ are removed)\n","* By default, the regular expression that is used to split the text and create tokens is : \"\\b\\w\\w+\\b\". This means it finds all sequences of characters that consist of at least two letters or numbers(\\w) and that are separated by word boundaries (\\b). It does not find single-letter words, and it splits up contractions like “doesn’t” or “bit.ly”, but it matches “h8ter” as a single word. The CountVectorizer then converts all words to lowercasecharacters, so that “soon”, “Soon”, and “sOon” all correspond to the same token (and therefore feature).\n","* It then creates a dictionary of unique words.\n","* The set of unique words is used as features in the CountVectorizer."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1662989153152,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"ayvQssZBRTNr","outputId":"50612156-3d47-49f2-93a3-1bd07f67cf93","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'count': 2,\n"," 'vectorizer': 17,\n"," 'for': 5,\n"," 'this': 16,\n"," 'scoring': 14,\n"," 'is': 8,\n"," 'done': 3,\n"," 'based': 0,\n"," 'on': 11,\n"," 'frequency': 6,\n"," 'key': 9,\n"," 'tfidf': 15,\n"," 'higher': 7,\n"," 'score': 13,\n"," 'binary': 1,\n"," 'presence': 12,\n"," 'of': 10,\n"," 'word': 18,\n"," 'dummy': 4}"]},"metadata":{},"execution_count":11}],"source":["# Let us see the dictionary created \n","vectorizer.vocabulary_"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1662989153152,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"4Z1haa0zRkXM","outputId":"76d8021d-2abb-4755-eccd-862a45fbe4fe","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["['based' 'binary' 'count' 'done' 'dummy' 'for' 'frequency' 'higher' 'is'\n"," 'key' 'of' 'on' 'presence' 'score' 'scoring' 'tfidf' 'this' 'vectorizer'\n"," 'word']\n","19\n"]}],"source":["# The set of unique words is used as features in the CountVectorizer\n","features = vectorizer.get_feature_names_out()\n","print(features)\n","print(len(features))"]},{"cell_type":"markdown","metadata":{"id":"mP8odLcIC66i"},"source":["## <font color = 'pickle'>**Generate Vectors using Vocab**"]},{"cell_type":"markdown","metadata":{"id":"9DwforYaDNsY"},"source":["### <font color = 'pickle'>**Binary Vectorizer**"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1662989153153,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"5x5YgOMdDiYC","outputId":"e10b5ab6-c5d3-4b75-8e3d-de495de57e20","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CountVectorizer(binary=True)"]},"metadata":{},"execution_count":13}],"source":["binary_vectorizer = CountVectorizer(binary=True)\n","binary_vectorizer.fit(Corpus)"]},{"cell_type":"markdown","metadata":{"id":"X4k8F2UTE4SU"},"source":["- We can now call transform() method to transform sentences in our corpus to vectors\n","- Each sentence in vocab will be represented by vector of length equal to len(dictionary)\n","- The vectors are stored in the form of a sparse matrix.\n","- We can use toarray() function to get complete matrix\n","- Number of columns represent the number of features (len(vocab))\n","- Number of rows represent the number the sentences in a corpus\n","- For each row, the numbers displayed are 0 or 1 - indicating absence or presence of a word in a sentence."]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-09-11T20:25:24.312760Z","iopub.status.busy":"2021-09-11T20:25:24.312601Z","iopub.status.idle":"2021-09-11T20:25:24.315437Z","shell.execute_reply":"2021-09-11T20:25:24.315041Z","shell.execute_reply.started":"2021-09-11T20:25:24.312747Z"},"id":"DzwuRnsInKHa","tags":[],"executionInfo":{"status":"ok","timestamp":1662989153153,"user_tz":300,"elapsed":11,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["binary_vectors = binary_vectorizer.transform(Corpus)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1662989153153,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"kfXmM7P3nVYy","outputId":"b73bb2bd-cbd6-4bef-8832-94fe03e94676","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["vectors in sparse format\n","  (0, 0)\t1\n","  (0, 2)\t1\n","  (0, 3)\t1\n","  (0, 5)\t1\n","  (0, 6)\t1\n","  (0, 8)\t1\n","  (0, 9)\t1\n","  (0, 11)\t1\n","  (0, 14)\t1\n","  (0, 16)\t1\n","  (0, 17)\t1\n","  (1, 0)\t1\n","  (1, 3)\t1\n","  (1, 5)\t1\n","  (1, 7)\t1\n","  (1, 8)\t1\n","  (1, 11)\t1\n","  (1, 13)\t1\n","  (1, 14)\t1\n","  (1, 15)\t1\n","  (1, 16)\t1\n","  (1, 17)\t1\n","  (2, 0)\t1\n","  (2, 1)\t1\n","  (2, 3)\t1\n","  (2, 4)\t1\n","  (2, 5)\t1\n","  (2, 8)\t1\n","  (2, 9)\t1\n","  (2, 10)\t1\n","  (2, 11)\t1\n","  (2, 12)\t1\n","  (2, 14)\t1\n","  (2, 16)\t1\n","  (2, 17)\t1\n","  (2, 18)\t1\n"]}],"source":["print(f'vectors in sparse format') \n","print(binary_vectors)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1662989153153,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"pr4aHet7Z3t_","outputId":"c315569e-d708-4b5f-901a-80deba262941"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","binary vectors in array(dense) format\n","[[1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0]\n"," [1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0]\n"," [1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1]]\n","\n","The shape of the binary vectors is : (3, 19)\n"]}],"source":["print(f'\\nbinary vectors in array(dense) format') \n","print(binary_vectors.toarray())\n","print(f'\\nThe shape of the binary vectors is : {binary_vectors.toarray().shape}')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1662989153154,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"3otH8XphHQJX","outputId":"125d9d3d-c423-441a-c752-db87ec466812"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   based  binary  count  done  dummy  for  frequency  higher  is  key  of  on  \\\n","0      1       0      1     1      0    1          1       0   1    1   0   1   \n","1      1       0      0     1      0    1          0       1   1    0   0   1   \n","2      1       1      0     1      1    1          0       0   1    1   1   1   \n","\n","   presence  score  scoring  tfidf  this  vectorizer  word  \n","0         0      0        1      0     1           1     0  \n","1         0      1        1      1     1           1     0  \n","2         1      0        1      0     1           1     1  "],"text/html":["\n","  <div id=\"df-3838a3f4-1320-4f2f-8956-ac38140324db\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>based</th>\n","      <th>binary</th>\n","      <th>count</th>\n","      <th>done</th>\n","      <th>dummy</th>\n","      <th>for</th>\n","      <th>frequency</th>\n","      <th>higher</th>\n","      <th>is</th>\n","      <th>key</th>\n","      <th>of</th>\n","      <th>on</th>\n","      <th>presence</th>\n","      <th>score</th>\n","      <th>scoring</th>\n","      <th>tfidf</th>\n","      <th>this</th>\n","      <th>vectorizer</th>\n","      <th>word</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3838a3f4-1320-4f2f-8956-ac38140324db')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3838a3f4-1320-4f2f-8956-ac38140324db button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3838a3f4-1320-4f2f-8956-ac38140324db');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}],"source":["# create dataframe for better visualization\n","df_binary = pd.DataFrame(binary_vectors.toarray(), columns = features)\n","df_binary"]},{"cell_type":"markdown","metadata":{"id":"OAPPPILCATX-"},"source":["### <font color = 'pickle'>**Count Vectorizer**\n","-  The vectors are stored in the form of a sparse matrix.\n","- Number of columns represent the number of features (len(vocab))\n","- Number of rows represent the number the sentences in a corpus\n","- Thus, each sentence is represented by a vector of size of length of vocab.\n","- For each row, the numbers displayed are the number of times a particular word has occurred in the sentence."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1662989153154,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"PuF8IkLUA8zp","outputId":"a7ddc888-c082-4fae-fc5f-77b70b900500","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["count vectors in array (dense) format\n","\n","[[1 0 1 1 0 2 4 0 2 1 0 1 0 0 1 0 2 4 0]\n"," [1 0 0 1 0 1 0 2 1 0 0 1 0 1 1 4 1 3 0]\n"," [1 1 0 1 3 2 0 0 2 1 1 1 1 0 1 0 2 4 1]]\n","\n","The shape of the count vectors is : (3, 19)\n"]}],"source":["term_freq_vectorizer = CountVectorizer(binary=False)\n","# we can combine fit and transform steps into a single step using fit_transform()\n","count_vectors = term_freq_vectorizer.fit_transform(Corpus)\n","print(f'count vectors in array (dense) format\\n') \n","print(count_vectors.toarray())\n","print(f'\\nThe shape of the count vectors is : {count_vectors.toarray().shape}')"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1662989153154,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"DLJCKNMVH0nm","outputId":"f9bfb579-2330-43c0-bf8e-367917d15d19"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   based  binary  count  done  dummy  for  frequency  higher  is  key  of  on  \\\n","0      1       0      1     1      0    2          4       0   2    1   0   1   \n","1      1       0      0     1      0    1          0       2   1    0   0   1   \n","2      1       1      0     1      3    2          0       0   2    1   1   1   \n","\n","   presence  score  scoring  tfidf  this  vectorizer  word  \n","0         0      0        1      0     2           4     0  \n","1         0      1        1      4     1           3     0  \n","2         1      0        1      0     2           4     1  "],"text/html":["\n","  <div id=\"df-76132c37-009f-4b7f-a23a-18580e8b8a09\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>based</th>\n","      <th>binary</th>\n","      <th>count</th>\n","      <th>done</th>\n","      <th>dummy</th>\n","      <th>for</th>\n","      <th>frequency</th>\n","      <th>higher</th>\n","      <th>is</th>\n","      <th>key</th>\n","      <th>of</th>\n","      <th>on</th>\n","      <th>presence</th>\n","      <th>score</th>\n","      <th>scoring</th>\n","      <th>tfidf</th>\n","      <th>this</th>\n","      <th>vectorizer</th>\n","      <th>word</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76132c37-009f-4b7f-a23a-18580e8b8a09')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-76132c37-009f-4b7f-a23a-18580e8b8a09 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-76132c37-009f-4b7f-a23a-18580e8b8a09');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}],"source":["# create dataframe for better visualization\n","df_count = pd.DataFrame(count_vectors.toarray(), columns = term_freq_vectorizer.get_feature_names_out())\n","df_count"]},{"cell_type":"markdown","metadata":{"id":"dVlJmMtmhCYM"},"source":["### <font color = 'pickle'>**tf-idf Vectorizer**\n","\n","- One measure of how important a word is term frequency (tf) (how frequently a word occurs in a document). We examined term frequency in previous sections where we used CountVectorizer to get the freqency of each word.\n","- But there may be words in a document, that occur many times but these words also occur in all other documents as well.\n","- Therefore the word mght not be a good representation of the document.\n","- We can account for this by giving more importance to words that occur in fewer documents using inverse document frequency((# Number of documents) / (Number of documents containing the word)).\n","- This can be combined with term frequency to calculate a term’s tf-idf (the two quantities multiplied together), the frequency of a term adjusted for how rarely it is used.\n","- The idea of tf-idf is to find the important words for the content of each document by decreasing the weight for commonly used words and increasing the weight for words that are not used very much in a collection or corpus of documents.\n","- tf-idf gives more weight to the the words that are important (i.e., occur more frequently) in a given document, but occur rarely in other documents."]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":116,"status":"ok","timestamp":1662989153262,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"hmb0UrD_xCEo","outputId":"625a11e8-7ca7-4fc6-873e-2f67d06df9d4","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["tfidf vectors in array (dense) format\n","\n","[[0.11016796 0.         0.18653056 0.11016796 0.         0.22033591\n","  0.74612225 0.         0.22033591 0.1418613  0.         0.11016796\n","  0.         0.         0.11016796 0.         0.22033591 0.44067182\n","  0.        ]\n"," [0.11455596 0.         0.         0.11455596 0.         0.11455596\n","  0.         0.3879202  0.11455596 0.         0.         0.11455596\n","  0.         0.1939601  0.11455596 0.77584039 0.11455596 0.34366788\n","  0.        ]\n"," [0.11874019 0.20104462 0.         0.11874019 0.60313387 0.23748039\n","  0.         0.         0.23748039 0.15289962 0.20104462 0.11874019\n","  0.20104462 0.         0.11874019 0.         0.23748039 0.47496077\n","  0.20104462]]\n","\n","The shape of the tfidf vectors is : (3, 19)\n"]}],"source":["tfidf_vectorizer = TfidfVectorizer()\n","# we can combine fit and transform steps into a single step using fit_transform()\n","tfidf_vectors = tfidf_vectorizer.fit_transform(Corpus)\n","print(f'tfidf vectors in array (dense) format\\n') \n","print(tfidf_vectors.toarray())\n","print(f'\\nThe shape of the tfidf vectors is : {tfidf_vectors.toarray().shape}')"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1662989153263,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"rz8SIqG_IZo1","outputId":"c151fd96-c9fb-46a7-f6d4-a96cf1678138"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    based  binary   count    done   dummy     for  frequency  higher      is  \\\n","0  0.1102   0.000  0.1865  0.1102  0.0000  0.2203     0.7461  0.0000  0.2203   \n","1  0.1146   0.000  0.0000  0.1146  0.0000  0.1146     0.0000  0.3879  0.1146   \n","2  0.1187   0.201  0.0000  0.1187  0.6031  0.2375     0.0000  0.0000  0.2375   \n","\n","      key     of      on  presence  score  scoring   tfidf    this  \\\n","0  0.1419  0.000  0.1102     0.000  0.000   0.1102  0.0000  0.2203   \n","1  0.0000  0.000  0.1146     0.000  0.194   0.1146  0.7758  0.1146   \n","2  0.1529  0.201  0.1187     0.201  0.000   0.1187  0.0000  0.2375   \n","\n","   vectorizer   word  \n","0      0.4407  0.000  \n","1      0.3437  0.000  \n","2      0.4750  0.201  "],"text/html":["\n","  <div id=\"df-4f8c6ebd-124f-4b53-a1ef-b516c666bc19\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>based</th>\n","      <th>binary</th>\n","      <th>count</th>\n","      <th>done</th>\n","      <th>dummy</th>\n","      <th>for</th>\n","      <th>frequency</th>\n","      <th>higher</th>\n","      <th>is</th>\n","      <th>key</th>\n","      <th>of</th>\n","      <th>on</th>\n","      <th>presence</th>\n","      <th>score</th>\n","      <th>scoring</th>\n","      <th>tfidf</th>\n","      <th>this</th>\n","      <th>vectorizer</th>\n","      <th>word</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.1102</td>\n","      <td>0.000</td>\n","      <td>0.1865</td>\n","      <td>0.1102</td>\n","      <td>0.0000</td>\n","      <td>0.2203</td>\n","      <td>0.7461</td>\n","      <td>0.0000</td>\n","      <td>0.2203</td>\n","      <td>0.1419</td>\n","      <td>0.000</td>\n","      <td>0.1102</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.1102</td>\n","      <td>0.0000</td>\n","      <td>0.2203</td>\n","      <td>0.4407</td>\n","      <td>0.000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.1146</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","      <td>0.1146</td>\n","      <td>0.0000</td>\n","      <td>0.1146</td>\n","      <td>0.0000</td>\n","      <td>0.3879</td>\n","      <td>0.1146</td>\n","      <td>0.0000</td>\n","      <td>0.000</td>\n","      <td>0.1146</td>\n","      <td>0.000</td>\n","      <td>0.194</td>\n","      <td>0.1146</td>\n","      <td>0.7758</td>\n","      <td>0.1146</td>\n","      <td>0.3437</td>\n","      <td>0.000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.1187</td>\n","      <td>0.201</td>\n","      <td>0.0000</td>\n","      <td>0.1187</td>\n","      <td>0.6031</td>\n","      <td>0.2375</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.2375</td>\n","      <td>0.1529</td>\n","      <td>0.201</td>\n","      <td>0.1187</td>\n","      <td>0.201</td>\n","      <td>0.000</td>\n","      <td>0.1187</td>\n","      <td>0.0000</td>\n","      <td>0.2375</td>\n","      <td>0.4750</td>\n","      <td>0.201</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f8c6ebd-124f-4b53-a1ef-b516c666bc19')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4f8c6ebd-124f-4b53-a1ef-b516c666bc19 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4f8c6ebd-124f-4b53-a1ef-b516c666bc19');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}],"source":["# create dataframe for better visualization\n","df_tfidf = pd.DataFrame(tfidf_vectors.toarray(), columns = tfidf_vectorizer.get_feature_names_out())\n","df_tfidf.round(4)"]},{"cell_type":"markdown","metadata":{"id":"nq8pvYnkxCEo"},"source":["### <font color = 'pickle'>**Undertstanding tfidf calculations**"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-09-11T20:59:13.152712Z","iopub.status.busy":"2021-09-11T20:59:13.152444Z","iopub.status.idle":"2021-09-11T20:59:13.158508Z","shell.execute_reply":"2021-09-11T20:59:13.157542Z","shell.execute_reply.started":"2021-09-11T20:59:13.152683Z"},"id":"wSoWEk3DxCEo","tags":[]},"source":["By default <br> \n","$\\text{tfidf}(w, d) = \\text{tf(w, d)} * \\text{idf(w)}$\n","<br>\n","$\\text{idf(w)} = \\log\\big(\\frac{N + 1}{N_w + 1}\\big) + 1$\n","<br><br>\n","if smooth_idf = False (default is True):\n","<br>\n","$\\text{idf(w)} = \\log\\big(\\frac{N }{N_w}\\big) + 1$\n","<br><br>\n","if sublinear_tfbool = True (default is False)\n","<br>\n","$\\text{tf(w, d)} = \\log(\\text{tf(w, d)} ) + 1$\n","\n","Here:<br>\n","- $\\text{tf}(w, d)$ is number of times word $w$ appears in document $d$ \n","<br>\n","- $\\text{idf}(w)$ is inverse documsnt frequency of word $w$\n","- $N$ is total number of documents\n","- $N_w$ is number of documents taht contaon word w"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1662989153263,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"fuTBzPljxCEo","outputId":"479bdc4e-2a0b-420b-b1be-a6fe8c9bb1dc","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.        , 1.69314718, 1.69314718, 1.        , 1.69314718,\n","       1.        , 1.69314718, 1.69314718, 1.        , 1.28768207,\n","       1.69314718, 1.        , 1.69314718, 1.69314718, 1.        ,\n","       1.69314718, 1.        , 1.        , 1.69314718])"]},"metadata":{},"execution_count":22}],"source":["# Calculate inverse document frequency for each feature (word)\n","term_idf = tfidf_vectorizer.idf_\n","term_idf"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1662989153263,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"GnwOVSQbJhVf","outputId":"09450669-ab0a-44c0-b15c-4e54ae7d9863"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   based  binary   count  done   dummy  for  frequency  higher   is     key  \\\n","0    1.0  1.6931  1.6931   1.0  1.6931  1.0     1.6931  1.6931  1.0  1.2877   \n","\n","       of   on  presence   score  scoring   tfidf  this  vectorizer    word  \n","0  1.6931  1.0    1.6931  1.6931      1.0  1.6931   1.0         1.0  1.6931  "],"text/html":["\n","  <div id=\"df-00d58759-de13-4593-bf87-3a14336da846\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>based</th>\n","      <th>binary</th>\n","      <th>count</th>\n","      <th>done</th>\n","      <th>dummy</th>\n","      <th>for</th>\n","      <th>frequency</th>\n","      <th>higher</th>\n","      <th>is</th>\n","      <th>key</th>\n","      <th>of</th>\n","      <th>on</th>\n","      <th>presence</th>\n","      <th>score</th>\n","      <th>scoring</th>\n","      <th>tfidf</th>\n","      <th>this</th>\n","      <th>vectorizer</th>\n","      <th>word</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>1.6931</td>\n","      <td>1.6931</td>\n","      <td>1.0</td>\n","      <td>1.6931</td>\n","      <td>1.0</td>\n","      <td>1.6931</td>\n","      <td>1.6931</td>\n","      <td>1.0</td>\n","      <td>1.2877</td>\n","      <td>1.6931</td>\n","      <td>1.0</td>\n","      <td>1.6931</td>\n","      <td>1.6931</td>\n","      <td>1.0</td>\n","      <td>1.6931</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.6931</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00d58759-de13-4593-bf87-3a14336da846')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-00d58759-de13-4593-bf87-3a14336da846 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-00d58759-de13-4593-bf87-3a14336da846');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}],"source":["# create dataframe for better visualization\n","df_idf = pd.DataFrame(term_idf, index = tfidf_vectorizer.get_feature_names_out())\n","df_idf.round(4).T"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"executionInfo":{"elapsed":230,"status":"ok","timestamp":1662989153490,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"Xs7vpUUZxCEo","outputId":"7af25cb6-84a2-41cc-fb4d-309f46001229","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      features  tf       idf  norm_tfidf\n","6    frequency   4  1.693147    0.746122\n","17  vectorizer   4  1.000000    0.440672\n","16        this   2  1.000000    0.220336\n","5          for   2  1.000000    0.220336\n","8           is   2  1.000000    0.220336\n","2        count   1  1.693147    0.186531\n","9          key   1  1.287682    0.141861\n","11          on   1  1.000000    0.110168\n","14     scoring   1  1.000000    0.110168\n","0        based   1  1.000000    0.110168\n","3         done   1  1.000000    0.110168\n","10          of   0  1.693147    0.000000\n","1       binary   0  1.693147    0.000000\n","12    presence   0  1.693147    0.000000\n","13       score   0  1.693147    0.000000\n","7       higher   0  1.693147    0.000000\n","15       tfidf   0  1.693147    0.000000\n","4        dummy   0  1.693147    0.000000\n","18        word   0  1.693147    0.000000"],"text/html":["\n","  <div id=\"df-ee48b554-28f4-43e4-82d5-1ca4f8c7bbf1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>features</th>\n","      <th>tf</th>\n","      <th>idf</th>\n","      <th>norm_tfidf</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6</th>\n","      <td>frequency</td>\n","      <td>4</td>\n","      <td>1.693147</td>\n","      <td>0.746122</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>vectorizer</td>\n","      <td>4</td>\n","      <td>1.000000</td>\n","      <td>0.440672</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>this</td>\n","      <td>2</td>\n","      <td>1.000000</td>\n","      <td>0.220336</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>for</td>\n","      <td>2</td>\n","      <td>1.000000</td>\n","      <td>0.220336</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>is</td>\n","      <td>2</td>\n","      <td>1.000000</td>\n","      <td>0.220336</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>count</td>\n","      <td>1</td>\n","      <td>1.693147</td>\n","      <td>0.186531</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>key</td>\n","      <td>1</td>\n","      <td>1.287682</td>\n","      <td>0.141861</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>on</td>\n","      <td>1</td>\n","      <td>1.000000</td>\n","      <td>0.110168</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>scoring</td>\n","      <td>1</td>\n","      <td>1.000000</td>\n","      <td>0.110168</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>based</td>\n","      <td>1</td>\n","      <td>1.000000</td>\n","      <td>0.110168</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>done</td>\n","      <td>1</td>\n","      <td>1.000000</td>\n","      <td>0.110168</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>of</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>binary</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>presence</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>score</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>higher</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>tfidf</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>dummy</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>word</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee48b554-28f4-43e4-82d5-1ca4f8c7bbf1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ee48b554-28f4-43e4-82d5-1ca4f8c7bbf1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ee48b554-28f4-43e4-82d5-1ca4f8c7bbf1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}],"source":["# create dataframe for tf vectors for the first document\n","\n","first_document_tf = count_vectors[0].toarray().ravel()\n","feature_names_tf = term_freq_vectorizer.get_feature_names_out()\n","df_tf = pd.DataFrame({'features':feature_names_tf, 'tf':first_document_tf})\n","\n","# create dataframe for tfidf vectors for the first document\n","\n","first_document_tfidf = tfidf_vectors[0].toarray().ravel()\n","feature_names_tfidf = tfidf_vectorizer.get_feature_names_out()\n","df_tfidf = pd.DataFrame({'features':feature_names_tfidf , 'idf':term_idf, 'norm_tfidf':first_document_tfidf})\n","\n","# combine dataframes\n","\n","df = pd.merge(left = df_tf, right = df_tfidf)\n","df.sort_values(by=[\"norm_tfidf\"],ascending=False, inplace = True)\n","df"]},{"cell_type":"markdown","metadata":{"id":"Ft1Jj6GfxCEo"},"source":["**Observations from above results**\n","- words 'frequency' and 'vectorizer' occurs 4 times in the documsnt and hence term frequency is 4.\n","- Word 'vectorizer' occurs in every documsnt and hence idf is 1 (log(1) + 1).\n","- norm_tfidf gives higher score to word 'frequency' than 'vectorizer'.\n","- norm_tfidf is not equal to idf * tf\n","\n","Let us know understand how norm_tfidf is calculated:"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2021-09-11T19:08:38.389005Z","iopub.status.busy":"2021-09-11T19:08:38.388843Z","iopub.status.idle":"2021-09-11T19:08:38.392671Z","shell.execute_reply":"2021-09-11T19:08:38.392237Z","shell.execute_reply.started":"2021-09-11T19:08:38.388992Z"},"id":"-k9PB58_xCEo","tags":[],"executionInfo":{"status":"ok","timestamp":1662989153490,"user_tz":300,"elapsed":8,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# calculate tfidf (without any normalization)\n","df['tfidf'] = df.eval('tf*idf')"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"execution":{"iopub.execute_input":"2021-09-12T03:13:47.640165Z","iopub.status.busy":"2021-09-12T03:13:47.639897Z","iopub.status.idle":"2021-09-12T03:13:47.651782Z","shell.execute_reply":"2021-09-12T03:13:47.651488Z","shell.execute_reply.started":"2021-09-12T03:13:47.640137Z"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1662989153491,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"Betig4AjxCEp","outputId":"e5cca2ec-b660-44ab-91db-790c75c63327","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      features  tf       idf  norm_tfidf     tfidf   sq_tfidf  \\\n","6    frequency   4  1.693147    0.746122  6.772589  45.867958   \n","17  vectorizer   4  1.000000    0.440672  4.000000  16.000000   \n","16        this   2  1.000000    0.220336  2.000000   4.000000   \n","5          for   2  1.000000    0.220336  2.000000   4.000000   \n","8           is   2  1.000000    0.220336  2.000000   4.000000   \n","2        count   1  1.693147    0.186531  1.693147   2.866747   \n","9          key   1  1.287682    0.141861  1.287682   1.658125   \n","11          on   1  1.000000    0.110168  1.000000   1.000000   \n","14     scoring   1  1.000000    0.110168  1.000000   1.000000   \n","0        based   1  1.000000    0.110168  1.000000   1.000000   \n","3         done   1  1.000000    0.110168  1.000000   1.000000   \n","10          of   0  1.693147    0.000000  0.000000   0.000000   \n","1       binary   0  1.693147    0.000000  0.000000   0.000000   \n","12    presence   0  1.693147    0.000000  0.000000   0.000000   \n","13       score   0  1.693147    0.000000  0.000000   0.000000   \n","7       higher   0  1.693147    0.000000  0.000000   0.000000   \n","15       tfidf   0  1.693147    0.000000  0.000000   0.000000   \n","4        dummy   0  1.693147    0.000000  0.000000   0.000000   \n","18        word   0  1.693147    0.000000  0.000000   0.000000   \n","\n","    norm_tfidf_manually  \n","6              0.746122  \n","17             0.440672  \n","16             0.220336  \n","5              0.220336  \n","8              0.220336  \n","2              0.186531  \n","9              0.141861  \n","11             0.110168  \n","14             0.110168  \n","0              0.110168  \n","3              0.110168  \n","10             0.000000  \n","1              0.000000  \n","12             0.000000  \n","13             0.000000  \n","7              0.000000  \n","15             0.000000  \n","4              0.000000  \n","18             0.000000  "],"text/html":["\n","  <div id=\"df-afb05db4-fc15-4560-af73-a3676f67e62c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>features</th>\n","      <th>tf</th>\n","      <th>idf</th>\n","      <th>norm_tfidf</th>\n","      <th>tfidf</th>\n","      <th>sq_tfidf</th>\n","      <th>norm_tfidf_manually</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6</th>\n","      <td>frequency</td>\n","      <td>4</td>\n","      <td>1.693147</td>\n","      <td>0.746122</td>\n","      <td>6.772589</td>\n","      <td>45.867958</td>\n","      <td>0.746122</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>vectorizer</td>\n","      <td>4</td>\n","      <td>1.000000</td>\n","      <td>0.440672</td>\n","      <td>4.000000</td>\n","      <td>16.000000</td>\n","      <td>0.440672</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>this</td>\n","      <td>2</td>\n","      <td>1.000000</td>\n","      <td>0.220336</td>\n","      <td>2.000000</td>\n","      <td>4.000000</td>\n","      <td>0.220336</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>for</td>\n","      <td>2</td>\n","      <td>1.000000</td>\n","      <td>0.220336</td>\n","      <td>2.000000</td>\n","      <td>4.000000</td>\n","      <td>0.220336</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>is</td>\n","      <td>2</td>\n","      <td>1.000000</td>\n","      <td>0.220336</td>\n","      <td>2.000000</td>\n","      <td>4.000000</td>\n","      <td>0.220336</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>count</td>\n","      <td>1</td>\n","      <td>1.693147</td>\n","      <td>0.186531</td>\n","      <td>1.693147</td>\n","      <td>2.866747</td>\n","      <td>0.186531</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>key</td>\n","      <td>1</td>\n","      <td>1.287682</td>\n","      <td>0.141861</td>\n","      <td>1.287682</td>\n","      <td>1.658125</td>\n","      <td>0.141861</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>on</td>\n","      <td>1</td>\n","      <td>1.000000</td>\n","      <td>0.110168</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.110168</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>scoring</td>\n","      <td>1</td>\n","      <td>1.000000</td>\n","      <td>0.110168</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.110168</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>based</td>\n","      <td>1</td>\n","      <td>1.000000</td>\n","      <td>0.110168</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.110168</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>done</td>\n","      <td>1</td>\n","      <td>1.000000</td>\n","      <td>0.110168</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.110168</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>of</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>binary</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>presence</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>score</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>higher</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>tfidf</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>dummy</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>word</td>\n","      <td>0</td>\n","      <td>1.693147</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afb05db4-fc15-4560-af73-a3676f67e62c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-afb05db4-fc15-4560-af73-a3676f67e62c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-afb05db4-fc15-4560-af73-a3676f67e62c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}],"source":["# calculate tfidf - normalized\n","df['sq_tfidf'] = df.eval('tfidf**2')\n","df['norm_tfidf_manually'] = df['tfidf']/np.sqrt(df['sq_tfidf'].sum())\n","df"]},{"cell_type":"markdown","metadata":{"id":"z1jKODj4iRNQ"},"source":["## <font color = 'pickle'>**Modifying Vocab**"]},{"cell_type":"markdown","metadata":{"id":"UeTUZZmJiccS"},"source":["### <font color = 'pickle'>**Case sensitive**"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T06:08:17.486661Z","iopub.status.busy":"2021-09-11T06:08:17.486532Z","iopub.status.idle":"2021-09-11T06:08:17.490721Z","shell.execute_reply":"2021-09-11T06:08:17.490336Z","shell.execute_reply.started":"2021-09-11T06:08:17.486649Z"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1662989153491,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"2omkpfjJnZ_L","outputId":"e8359716-a73b-4a5f-cdfe-151a71e3ebde"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Count': 1,\n"," 'Vectorizer': 3,\n"," 'for': 7,\n"," 'this': 18,\n"," 'vectorizer': 19,\n"," 'scoring': 16,\n"," 'is': 10,\n"," 'done': 5,\n"," 'based': 4,\n"," 'on': 13,\n"," 'frequency': 8,\n"," 'For': 2,\n"," 'key': 11,\n"," 'tfidf': 17,\n"," 'higher': 9,\n"," 'score': 15,\n"," 'Binary': 0,\n"," 'presence': 14,\n"," 'of': 12,\n"," 'word': 20,\n"," 'dummy': 6}"]},"metadata":{},"execution_count":27}],"source":["# lowercase=False to get feature name containing words for both lower and upper case\n","vectorizer = CountVectorizer(lowercase=False)\n","\n","# we can use fit_transform to use fit() and transform() in one step\n","vectors = vectorizer.fit_transform(Corpus)\n","vectorizer.vocabulary_"]},{"cell_type":"markdown","metadata":{"id":"75w3LP5li7VM"},"source":["### <font color = 'pickle'>**Filtering words based on frequency**"]},{"cell_type":"markdown","metadata":{"id":"RP_IKZG9jKvD"},"source":["- max_df - Ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n","- min_df -  Ignore terms that have a document frequency strictly lower than the given threshold (known as cut-off in the literature.) \n","\n","- max_features - build a vocabulary that only consider the top max_features ordered by term frequency across the corpus\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T06:08:40.000725Z","iopub.status.busy":"2021-09-11T06:08:40.000235Z","iopub.status.idle":"2021-09-11T06:08:40.007239Z","shell.execute_reply":"2021-09-11T06:08:40.006996Z","shell.execute_reply.started":"2021-09-11T06:08:40.000670Z"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1662989153491,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"YxzFCRGEMCkm","outputId":"2addd696-471a-42f6-efdc-cbf1a21bc8df"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'vectorizer': 8,\n"," 'for': 2,\n"," 'this': 7,\n"," 'scoring': 6,\n"," 'is': 3,\n"," 'done': 1,\n"," 'based': 0,\n"," 'on': 5,\n"," 'key': 4}"]},"metadata":{},"execution_count":28}],"source":["# remove rare words - remove words which appear in less than 2 documents\n","vectorizer = CountVectorizer(min_df=2)\n","vectorizer.fit(Corpus)\n","vectorizer.vocabulary_"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T06:09:31.316083Z","iopub.status.busy":"2021-09-11T06:09:31.315553Z","iopub.status.idle":"2021-09-11T06:09:31.322432Z","shell.execute_reply":"2021-09-11T06:09:31.322174Z","shell.execute_reply.started":"2021-09-11T06:09:31.316023Z"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1662989176202,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"bHDT20dLxCEq","outputId":"501010c9-dbeb-4ae6-a1ed-973b9474c1ff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'count': 1,\n"," 'frequency': 3,\n"," 'key': 5,\n"," 'tfidf': 9,\n"," 'higher': 4,\n"," 'score': 8,\n"," 'binary': 0,\n"," 'presence': 7,\n"," 'of': 6,\n"," 'word': 10,\n"," 'dummy': 2}"]},"metadata":{},"execution_count":31}],"source":["# remove words which appear in more than 2 documents\n","vectorizer = CountVectorizer(max_df=2)\n","vectorizer.fit(Corpus)\n","vectorizer.vocabulary_"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T06:10:33.933882Z","iopub.status.busy":"2021-09-11T06:10:33.933354Z","iopub.status.idle":"2021-09-11T06:10:33.940572Z","shell.execute_reply":"2021-09-11T06:10:33.940289Z","shell.execute_reply.started":"2021-09-11T06:10:33.933825Z"},"executionInfo":{"elapsed":91,"status":"ok","timestamp":1662989179456,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"UW_UErB8xCEq","outputId":"1f51ee8e-006b-4142-bb2b-13d146b7ed29"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'vectorizer': 4, 'for': 0, 'this': 3, 'is': 1, 'tfidf': 2}"]},"metadata":{},"execution_count":32}],"source":["# retain most frequent words only - retain top n words based on term frequency across corpus\n","vectorizer = CountVectorizer(max_features=5)\n","vectorizer.fit(Corpus)\n","vectorizer.vocabulary_"]},{"cell_type":"markdown","metadata":{"id":"F6mnf0ZHxCEq"},"source":["### <font color = 'pickle'>**Stop Words**"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T06:14:28.793903Z","iopub.status.busy":"2021-09-11T06:14:28.793490Z","iopub.status.idle":"2021-09-11T06:14:28.800896Z","shell.execute_reply":"2021-09-11T06:14:28.800576Z","shell.execute_reply.started":"2021-09-11T06:14:28.793866Z"},"executionInfo":{"elapsed":97,"status":"ok","timestamp":1662989180768,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"XZ4dTc6YxCEq","outputId":"a9515935-2698-41f5-8250-6a94fc157148"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'vectorizer': 4, 'done': 1, 'based': 0, 'frequency': 2, 'tfidf': 3}"]},"metadata":{},"execution_count":33}],"source":["# We can also specify list of stopwords to countvectorizer to get the feature without stopwords\n","\n","# Import libraries\n","nltk_stop_words = stopwords.words('english')\n","\n","vectorizer = CountVectorizer(max_features=5, stop_words= nltk_stop_words)\n","vectorizer.fit(Corpus)\n","vectorizer.vocabulary_"]},{"cell_type":"markdown","metadata":{"id":"OWwFq44kxCEq"},"source":["### <font color = 'pickle'>**Custom Tokenizer and Preprocessor**"]},{"cell_type":"markdown","metadata":{"id":"MrVX1WEtxCEq"},"source":["#### <font color = 'pickle'>**nltk tokenizer**"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-12T03:16:09.705726Z","iopub.status.busy":"2021-09-12T03:16:09.705542Z","iopub.status.idle":"2021-09-12T03:16:09.711195Z","shell.execute_reply":"2021-09-12T03:16:09.710860Z","shell.execute_reply.started":"2021-09-12T03:16:09.705710Z"},"executionInfo":{"elapsed":110,"status":"ok","timestamp":1662989181736,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"XrmIi5seqljd","outputId":"7cc1c4bc-bd85-4d14-d0ee-dd8745e61a44","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'count': 11,\n"," 'vectorizer': 26,\n"," '-': 4,\n"," 'for': 14,\n"," 'this': 25,\n"," ',': 3,\n"," 'scoring': 23,\n"," 'is': 17,\n"," 'done': 12,\n"," 'based': 9,\n"," 'on': 20,\n"," 'frequency': 15,\n"," '.': 5,\n"," 'key': 18,\n"," '@vectorizer': 8,\n"," '#frequency': 1,\n"," '@frequency': 7,\n"," 'tfidf': 24,\n"," 'higher': 16,\n"," 'score': 22,\n"," '#tfidf': 2,\n"," 'binary': 10,\n"," 'presence': 21,\n"," 'of': 19,\n"," 'word': 27,\n"," 'dummy': 13,\n"," '#dummy': 0,\n"," '@dummy': 6}"]},"metadata":{},"execution_count":34}],"source":["# We can use custom tokenizere.g. we can use nltk tweet tokenizer to get each tokens as feature\n","\n","# Create an object of TweetTokenizer class\n","tweet_tokenizer = TweetTokenizer()\n","\n","# Pass the tokenizer object to tokenizer argument in CountVectorizer\n","# only works if analyzer = 'word'\n","vectorizer = CountVectorizer(analyzer='word', tokenizer=tweet_tokenizer.tokenize)\n","\n","vectorizer.fit_transform(Corpus)\n","\n","vectorizer.vocabulary_"]},{"cell_type":"markdown","metadata":{"id":"nMzV-qHwxCEr"},"source":["#### <font color = 'pickle'>**spacy pre-processor and tokenizer**"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2021-09-12T03:16:12.204316Z","iopub.status.busy":"2021-09-12T03:16:12.204153Z","iopub.status.idle":"2021-09-12T03:16:12.207192Z","shell.execute_reply":"2021-09-12T03:16:12.206765Z","shell.execute_reply.started":"2021-09-12T03:16:12.204303Z"},"id":"nmyYzK9AVzXw","tags":[],"executionInfo":{"status":"ok","timestamp":1662989182688,"user_tz":300,"elapsed":186,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["def spacy_preprocessor(text):    \n","\n","    # Create spacy object\n","    doc = nlp(text)\n","\n","    # remove punctuations, apply lametization\n","    filtered_text = [token.lemma_ for token in doc if not token.is_punct]\n","  \n","    return \" \".join(filtered_text)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2021-09-12T03:16:12.863124Z","iopub.status.busy":"2021-09-12T03:16:12.862607Z","iopub.status.idle":"2021-09-12T03:16:12.872726Z","shell.execute_reply":"2021-09-12T03:16:12.870950Z","shell.execute_reply.started":"2021-09-12T03:16:12.863065Z"},"id":"YnFartqtWe6X","tags":[],"executionInfo":{"status":"ok","timestamp":1662989182789,"user_tz":300,"elapsed":1,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# Spacy Tokenizer\n","def spacy_tokenizer(data):\n","  doc=nlp(data)\n","  return [token.text for token in doc]"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T20:36:02.024537Z","iopub.status.busy":"2021-09-11T20:36:02.024028Z","iopub.status.idle":"2021-09-11T20:36:02.043042Z","shell.execute_reply":"2021-09-11T20:36:02.042678Z","shell.execute_reply.started":"2021-09-11T20:36:02.024478Z"},"executionInfo":{"elapsed":128,"status":"ok","timestamp":1662989183554,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"S0GAbq-3WsT_","outputId":"f8a8062c-e5d1-499b-9723-f010e7e3c1ca","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Count': 5,\n"," 'Vectorizer': 6,\n"," 'for': 12,\n"," 'this': 22,\n"," 'vectorizer': 23,\n"," 'scoring': 20,\n"," 'be': 8,\n"," 'done': 10,\n"," 'base': 7,\n"," 'on': 17,\n"," 'frequency': 13,\n"," 'key': 15,\n"," '@vectorizer': 4,\n"," '@frequency': 3,\n"," 'tfidf': 21,\n"," '  ': 0,\n"," 'high': 14,\n"," 'score': 19,\n"," 'binary': 9,\n"," '-for': 1,\n"," 'presence': 18,\n"," 'of': 16,\n"," 'word': 24,\n"," 'dummy': 11,\n"," '@dummy': 2}"]},"metadata":{},"execution_count":37}],"source":["# custom preprocessor and spacy tokenizer\n","vectorizer = CountVectorizer(analyzer='word', preprocessor=spacy_preprocessor , tokenizer=spacy_tokenizer, token_pattern=None)\n","vectors=vectorizer.fit(Corpus)\n","vectorizer.vocabulary_"]},{"cell_type":"markdown","metadata":{"id":"STiVvP5qxCEr"},"source":["#### <font color = 'pickle'>**token pattterns with regular expressions**"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T06:32:57.889450Z","iopub.status.busy":"2021-09-11T06:32:57.888935Z","iopub.status.idle":"2021-09-11T06:32:57.893152Z","shell.execute_reply":"2021-09-11T06:32:57.892901Z","shell.execute_reply.started":"2021-09-11T06:32:57.889434Z"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1662989183916,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"2xEae96cC5e3","outputId":"771b27a4-9635-4867-e49f-dd42086266fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'count': 10,\n"," 'vectorizer': 28,\n"," '-': 3,\n"," 'for': 13,\n"," 'this': 27,\n"," 'vectorizer,': 29,\n"," 'scoring': 24,\n"," 'is': 17,\n"," 'done': 11,\n"," 'based': 8,\n"," 'on': 21,\n"," 'frequency.': 15,\n"," 'frequency': 14,\n"," 'key.': 19,\n"," '@vectorizer': 7,\n"," '#frequency': 1,\n"," '@frequency': 6,\n"," 'tfidf': 25,\n"," 'tfidf,': 26,\n"," 'higher': 16,\n"," 'score': 23,\n"," '#tfidf': 2,\n"," 'binary': 9,\n"," '-for': 4,\n"," 'presence': 22,\n"," 'of': 20,\n"," 'word.': 30,\n"," 'dummy': 12,\n"," 'key': 18,\n"," '#dummy': 0,\n"," '@dummy': 5}"]},"metadata":{},"execution_count":38}],"source":["# We can pass regex to the argument token_pattern to get required pattern\n","# whitespace tokenizer\n","# This can be very useful if we have allready cleaned the text\n","vectorizer = CountVectorizer(analyzer='word', token_pattern=r\"[\\S]+\")\n","\n","# Assign the encoded(transformed) vectors to a variable\n","vectors = vectorizer.fit_transform(Corpus)\n","\n","vectorizer.vocabulary_"]},{"cell_type":"markdown","metadata":{"id":"haBuVWSyxCEs"},"source":["### <font color = 'pickle'>**ngrams**\n","\n","- Till now our features consists of single token. However, in some cases we may want to use sequence of tokens as features\n","- Consider the folowing corpus\n"," 1. This item is good\n"," 2. This item is not good\n","- Now  both the documents will have feature 'good' and 'not' will be an additional feature in document 2.\n","- For applications like sentiment analysis - it might be a good idea to consider 'not good' as a single token.\n","\n","- We can use ngram_range(min_n, max_n) in CountVectorizer to create features that consists of sequence of words.\n","\n","- We can get n-grams of required length by providing range (min_n, max_n)\n","\n","- if we specify min_n = 2 and max_n = 3 - we will get bigrams and trigrams as features."]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T06:47:29.553885Z","iopub.status.busy":"2021-09-11T06:47:29.553741Z","iopub.status.idle":"2021-09-11T06:47:29.559538Z","shell.execute_reply":"2021-09-11T06:47:29.559122Z","shell.execute_reply.started":"2021-09-11T06:47:29.553873Z"},"executionInfo":{"elapsed":92,"status":"ok","timestamp":1662989184747,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"Ix4jKILgDLxa","outputId":"b1894870-f35a-415a-8be0-f8a930077347","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Features for text 1\n","\n","is not\n","is not good\n","item is\n","item is not\n","not good\n","this item\n","this item is\n","\n","Features for text 2\n","\n","is good\n","item is\n","item is good\n","this item\n","this item is\n"]}],"source":["min_n = 2\n","max_n = 3\n","\n","# only works if analyzer = 'word'\n","vectorizer1 = CountVectorizer(analyzer = 'word', ngram_range=(min_n, max_n))\n","vectorizer2 = CountVectorizer(analyzer = 'word', ngram_range=(min_n, max_n))\n","\n","text1= [\"This item is not good\"]\n","text2 = [\"This item is good\"]\n","\n","# Fit the vectorizers to text\n","vectorizer1.fit_transform(text1)\n","vectorizer2.fit_transform(text2)\n","\n","features1 = vectorizer1.get_feature_names_out()\n","features2 = vectorizer2.get_feature_names_out()\n","\n","print('Features for text 1\\n')\n","for feature in features1:\n","  print(feature)\n","\n","print(f'\\nFeatures for text 2\\n')\n","for feature in features2:\n","  print(feature)"]},{"cell_type":"markdown","metadata":{"id":"7eaVPcHeRXRl"},"source":["## <font color = 'pickle'>**Example : IMDB Data set** "]},{"cell_type":"markdown","metadata":{"id":"wr_e08FxxCEs"},"source":["### <font color = 'pickle'>**Import Data**"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2021-09-11T07:45:50.456908Z","iopub.status.busy":"2021-09-11T07:45:50.456747Z","iopub.status.idle":"2021-09-11T07:45:50.459467Z","shell.execute_reply":"2021-09-11T07:45:50.459100Z","shell.execute_reply.started":"2021-09-11T07:45:50.456895Z"},"id":"TnakQosgOsMY","tags":[],"executionInfo":{"status":"ok","timestamp":1662989185873,"user_tz":300,"elapsed":140,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# Use train.csv of IMDB movie review data (we downloaded this in the last lecture)\n","train_data = data_folder / 'aclImdb'/'train.csv'\n","test_data = data_folder / 'aclImdb'/'test.csv'"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T07:41:27.376086Z","iopub.status.busy":"2021-09-11T07:41:27.375913Z","iopub.status.idle":"2021-09-11T07:41:27.497930Z","shell.execute_reply":"2021-09-11T07:41:27.497477Z","shell.execute_reply.started":"2021-09-11T07:41:27.376071Z"},"executionInfo":{"elapsed":1826,"status":"ok","timestamp":1662989187810,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"rLsuPS6lxCEs","outputId":"af37cb07-1024-4c49-9bbc-59743318c29d","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":[",Reviews,Labels\n","0,\"Ever wanted to know just how much Hollywood could get away with before the Hayes Code was officially put into effect? Well, unfortunately \"\"Convention City\"\" is lost, so well just have to watch \"\"Tarzan and His Mate\"\" to find out. For 1934, there is a remarkable amount of sexual innuendo and even exposed flesh. Just look at Jane's nude swim. While Tarzan is often thought of as b-adventure films made for young boys and no one else, this picture proves that the series was originally very adult. Over seventy years later, it is still as sexy as it was when it came out.<br /><br />In addition to the envelope pushing taboo nature, it is a superb and exciting adventure story. I've always enjoyed the jungle films that Hollywood churned out in the 30s and the 40s, but there are few from the genre I'd call great films. \"\"Tarzan and His Mate\"\" is by far the best film from this long gone subgenre. The sequences of the attacks on the safari by either apes or natives still manage to create tension today. Also, the animals are all too cool (espescially the apes throwing boulders). The acting won't win any major awards soon, but is certainly more than adequate for this type of picture. The film is once again stolen by Cheetah, the smartest monkey in the jungle. One of the most entertaining examples of pre-code Hollywood out there.\",1\n"]}],"source":["!head -n 2 {str(train_data)}"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"execution":{"iopub.execute_input":"2021-09-11T07:53:35.249495Z","iopub.status.busy":"2021-09-11T07:53:35.249349Z","iopub.status.idle":"2021-09-11T07:53:35.584630Z","shell.execute_reply":"2021-09-11T07:53:35.584212Z","shell.execute_reply.started":"2021-09-11T07:53:35.249483Z"},"executionInfo":{"elapsed":1309,"status":"ok","timestamp":1662989189739,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"2CgPhuOixCEs","outputId":"03214965-d1de-4378-8a54-9e9525cfd230","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of Training data set is : (25000, 2)\n","Shape of Test data set is : (25000, 2)\n","\n","Top five rows of Training data set:\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["                                             Reviews  Labels\n","0  Ever wanted to know just how much Hollywood co...       1\n","1  The movie itself was ok for the kids. But I go...       1\n","2  You could stage a version of Charles Dickens' ...       1\n","3  this was a fantastic episode. i saw a clip fro...       1\n","4  and laugh out loud funny in many scenes.<br />...       1"],"text/html":["\n","  <div id=\"df-c98e9498-7105-4663-b72c-9cd3f9042116\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Reviews</th>\n","      <th>Labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ever wanted to know just how much Hollywood co...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The movie itself was ok for the kids. But I go...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>You could stage a version of Charles Dickens' ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>this was a fantastic episode. i saw a clip fro...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>and laugh out loud funny in many scenes.&lt;br /&gt;...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c98e9498-7105-4663-b72c-9cd3f9042116')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c98e9498-7105-4663-b72c-9cd3f9042116 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c98e9498-7105-4663-b72c-9cd3f9042116');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":42}],"source":["# Reading data\n","train_df = pd.read_csv(train_data, index_col=0)\n","test_df = pd.read_csv(test_data, index_col=0)\n","print(f'Shape of Training data set is : {train_df.shape}')\n","print(f'Shape of Test data set is : {test_df.shape}')\n","print(f'\\nTop five rows of Training data set:\\n')\n","train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"FDh2M0G9xCEs"},"source":["### <font color = 'pickle'>**Generating Vocab**\n","- <font color = 'indianred'>**Vocab should be created only based on training dataset**</font>\n","- We will generate vocab using CountVectorizer\n","- <font color = 'indianred'>**Use fit_transform() on Training data set**. \n","- **Use only transform() on Test dataset**. This make sures that we generate vocab only based on training dataset."]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T07:46:54.988708Z","iopub.status.busy":"2021-09-11T07:46:54.988551Z","iopub.status.idle":"2021-09-11T07:46:57.356248Z","shell.execute_reply":"2021-09-11T07:46:57.355769Z","shell.execute_reply.started":"2021-09-11T07:46:54.988695Z"},"executionInfo":{"elapsed":3210,"status":"ok","timestamp":1662989192948,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"rudMW4B_UGVE","outputId":"d53aa683-a330-41eb-b746-3c48f1c8790a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CountVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n","                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n","                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n","                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n","                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n","                            'itself', ...])"]},"metadata":{},"execution_count":43}],"source":["# Initialize vectorizer\n","nltk_stop_words = stopwords.words('english')\n","bag_of_word = CountVectorizer(stop_words= nltk_stop_words)\n","\n","# Fit on training data\n","bag_of_word.fit(train_df['Reviews'].values)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2021-09-11T07:47:13.492919Z","iopub.status.busy":"2021-09-11T07:47:13.492761Z","iopub.status.idle":"2021-09-11T07:47:13.527237Z","shell.execute_reply":"2021-09-11T07:47:13.526788Z","shell.execute_reply.started":"2021-09-11T07:47:13.492905Z"},"id":"6DsUyK2LVCg4","tags":[],"executionInfo":{"status":"ok","timestamp":1662989192949,"user_tz":300,"elapsed":3,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# get feature names\n","features = bag_of_word.get_feature_names_out()"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T07:47:20.015894Z","iopub.status.busy":"2021-09-11T07:47:20.015734Z","iopub.status.idle":"2021-09-11T07:47:20.019068Z","shell.execute_reply":"2021-09-11T07:47:20.018602Z","shell.execute_reply.started":"2021-09-11T07:47:20.015881Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1662989193099,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"yIDLMOzoxCEt","outputId":"e1f75875-467e-49f0-ddb8-e8e145de5b75"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["74704"]},"metadata":{},"execution_count":45}],"source":["# check the legth of the vocab\n","len(features)"]},{"cell_type":"markdown","metadata":{"id":"MxjTROQkxCEt"},"source":["### <font color = 'pickle'>**Create vectors for reviews**"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2021-09-11T08:00:01.403847Z","iopub.status.busy":"2021-09-11T08:00:01.403637Z","iopub.status.idle":"2021-09-11T08:00:05.617042Z","shell.execute_reply":"2021-09-11T08:00:05.616588Z","shell.execute_reply.started":"2021-09-11T08:00:01.403825Z"},"id":"sUvgnrjZVJYn","executionInfo":{"status":"ok","timestamp":1662989199805,"user_tz":300,"elapsed":6708,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# Transform the training and test dataset \n","bow_vector_train = bag_of_word.transform(train_df['Reviews'].values)\n","bow_vector_test = bag_of_word.transform(test_df['Reviews'].values)"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T08:00:08.442306Z","iopub.status.busy":"2021-09-11T08:00:08.442071Z","iopub.status.idle":"2021-09-11T08:00:08.446901Z","shell.execute_reply":"2021-09-11T08:00:08.446266Z","shell.execute_reply.started":"2021-09-11T08:00:08.442282Z"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1662989199805,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"6xk4M3NPxCEt","outputId":"ce38807e-4410-482b-8a0c-ac9ae970f776"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<25000x74704 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 2479678 stored elements in Compressed Sparse Row format>"]},"metadata":{},"execution_count":47}],"source":["# Shape of the matrix for train dataset\n","bow_vector_train"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T08:00:56.304151Z","iopub.status.busy":"2021-09-11T08:00:56.303619Z","iopub.status.idle":"2021-09-11T08:00:56.314758Z","shell.execute_reply":"2021-09-11T08:00:56.312719Z","shell.execute_reply.started":"2021-09-11T08:00:56.304091Z"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1662989199806,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"_LALNShqxCEt","outputId":"62d6acf5-2782-46a4-9ccd-43d0586546b8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<25000x74704 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 2385031 stored elements in Compressed Sparse Row format>"]},"metadata":{},"execution_count":48}],"source":["# Shape of the matrix for train dataset\n","bow_vector_test"]},{"cell_type":"markdown","metadata":{"id":"uaUcb2LBXBhw"},"source":["### <font color = 'pickle'>**Limit vocab using max_features**\n","We got 25k rows with 78k+ features, but what if we want only top 5k features.\n","We can do this by providing max_features parameter."]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-09-11T08:02:16.620779Z","iopub.status.busy":"2021-09-11T08:02:16.620635Z","iopub.status.idle":"2021-09-11T08:02:18.859959Z","shell.execute_reply":"2021-09-11T08:02:18.859536Z","shell.execute_reply.started":"2021-09-11T08:02:16.620764Z"},"executionInfo":{"elapsed":3377,"status":"ok","timestamp":1662989203175,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"wWaQV1tkVM2L","outputId":"d3ba33a7-e3d2-4384-d1ee-2f325fbafd39"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n","  % sorted(inconsistent)\n"]},{"output_type":"execute_result","data":{"text/plain":["CountVectorizer(max_features=5000,\n","                stop_words={\"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", 'a', 'about',\n","                            'above', 'across', 'after', 'afterwards', 'again',\n","                            'against', 'all', 'almost', 'alone', 'along',\n","                            'already', 'also', 'although', 'always', 'am',\n","                            'among', 'amongst', 'amount', 'an', 'and',\n","                            'another', 'any', ...})"]},"metadata":{},"execution_count":49}],"source":["# Limit Vocab size using Max features\n","spacy_stop_words = nlp.Defaults.stop_words\n","bag_of_word = CountVectorizer(max_features=5000, stop_words= spacy_stop_words)  # Max features\n","\n","# Fit on training data\n","bag_of_word.fit(train_df['Reviews'].values)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2021-09-11T08:02:57.092677Z","iopub.status.busy":"2021-09-11T08:02:57.092551Z","iopub.status.idle":"2021-09-11T08:03:01.788423Z","shell.execute_reply":"2021-09-11T08:03:01.787845Z","shell.execute_reply.started":"2021-09-11T08:02:57.092664Z"},"id":"rEq04frRXq_i","executionInfo":{"status":"ok","timestamp":1662989213077,"user_tz":300,"elapsed":9905,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"outputs":[],"source":["# Transform the training and test dataset \n","bow_vector_train = bag_of_word.transform(train_df['Reviews'].values)\n","bow_vector_test = bag_of_word.transform(train_df['Reviews'].values)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"execution":{"iopub.execute_input":"2021-09-11T08:03:51.691500Z","iopub.status.busy":"2021-09-11T08:03:51.691259Z","iopub.status.idle":"2021-09-11T08:03:51.887702Z","shell.execute_reply":"2021-09-11T08:03:51.887320Z","shell.execute_reply.started":"2021-09-11T08:03:51.691476Z"},"executionInfo":{"elapsed":282,"status":"ok","timestamp":1662989213358,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"6EZxdHGaY2Ha","outputId":"4c4875b1-f03d-4a53-f384-b03d1a11a42e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       00  000  10  100  11  12  13  13th  14  15  ...  yesterday  york  \\\n","0       0    0   0    0   0   0   0     0   0   0  ...          0     0   \n","1       0    0   0    0   0   0   0     0   0   0  ...          0     0   \n","2       0    0   0    0   0   0   0     0   0   0  ...          0     1   \n","3       0    0   0    0   0   0   0     0   0   0  ...          0     0   \n","4       0    0   0    0   0   0   0     0   0   0  ...          0     0   \n","...    ..  ...  ..  ...  ..  ..  ..   ...  ..  ..  ...        ...   ...   \n","24995   0    0   0    0   0   0   0     0   0   0  ...          0     0   \n","24996   0    0   0    0   0   0   0     0   0   0  ...          0     0   \n","24997   0    0   0    0   0   0   0     0   0   1  ...          0     0   \n","24998   0    0   1    0   0   0   0     0   0   0  ...          0     0   \n","24999   0    0   0    0   0   0   0     0   0   0  ...          0     0   \n","\n","       young  younger  youth  zero  zizek  zombie  zombies  zone  \n","0          1        0      0     0      0       0        0     0  \n","1          0        0      0     0      0       0        0     0  \n","2          0        0      0     0      0       0        0     0  \n","3          0        0      0     0      0       0        0     0  \n","4          0        0      0     0      0       0        0     0  \n","...      ...      ...    ...   ...    ...     ...      ...   ...  \n","24995      0        0      0     0      0       0        0     0  \n","24996      0        0      0     0      0       0        0     0  \n","24997      0        1      0     0      0       0        0     0  \n","24998      0        0      0     0      0       0        0     0  \n","24999      0        0      0     0      0       0        0     0  \n","\n","[25000 rows x 5000 columns]"],"text/html":["\n","  <div id=\"df-7492a01c-f350-45d9-9e7a-a699deb36411\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>00</th>\n","      <th>000</th>\n","      <th>10</th>\n","      <th>100</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>13th</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>...</th>\n","      <th>yesterday</th>\n","      <th>york</th>\n","      <th>young</th>\n","      <th>younger</th>\n","      <th>youth</th>\n","      <th>zero</th>\n","      <th>zizek</th>\n","      <th>zombie</th>\n","      <th>zombies</th>\n","      <th>zone</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24995</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24996</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24997</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24998</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24999</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25000 rows × 5000 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7492a01c-f350-45d9-9e7a-a699deb36411')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7492a01c-f350-45d9-9e7a-a699deb36411 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7492a01c-f350-45d9-9e7a-a699deb36411');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":51}],"source":["# Document representation\n","vocab = bag_of_word.get_feature_names_out()\n","pd.DataFrame(bow_vector_train.toarray(), columns=vocab)"]},{"cell_type":"markdown","metadata":{"id":"XRxVC5p-Z03k"},"source":["---"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"pt10","language":"python","name":"pt10"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}